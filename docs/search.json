[
  {
    "objectID": "topics/r_lesson.html",
    "href": "topics/r_lesson.html",
    "title": "R Lesson",
    "section": "",
    "text": "R: Intro to Remote Sensing\nThis lesson presents a basic R script for analyzing data.\nLaunch in Binder\nDownload R Script\n\n\n# Generate 100 random numbers from normal distribution\nx &lt;- rnorm(100)\nsummary(x)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-2.325138 -0.696802  0.046372  0.005638  0.697964  1.916998 \n\n# Plot histogram\nhist(x, main = \"Histogram of x\", col = \"skyblue\", border = \"white\")\n\n\n\n\n\n\n\n\n\nWatch the video below:"
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html",
    "href": "topics/hyperspectral_tutorial.html",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "",
    "text": "This tutorial demonstrates how to analyze hyperspectral data for plant classification and biomarker estimation. We’ll work with spectral reflectance data from plant samples collected in different months (March and July) across various plant groups and classes. The analysis includes data preprocessing, visualization, statistical testing, and machine learning classification using both raw spectral data and derived vegetation indices."
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html#overview",
    "href": "topics/hyperspectral_tutorial.html#overview",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "",
    "text": "This tutorial demonstrates how to analyze hyperspectral data for plant classification and biomarker estimation. We’ll work with spectral reflectance data from plant samples collected in different months (March and July) across various plant groups and classes. The analysis includes data preprocessing, visualization, statistical testing, and machine learning classification using both raw spectral data and derived vegetation indices."
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html#prerequisites",
    "href": "topics/hyperspectral_tutorial.html#prerequisites",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\nBefore starting, you’ll need to download the data and install and load several R packages for data manipulation, visualization, and machine learning.\n\n# Install required packages (uncomment if needed)\n# install.packages(c(\"tidyverse\", \"ggpubr\", \"dplyr\", \"caret\", \"ggplot2\",\n#                    \"patchwork\", \"ggforce\", \"pls\"))\n# \n# # Install BiocManager and mixOmics for advanced multivariate analysis\n# install.packages(\"BiocManager\")\n# BiocManager::install(\"mixOmics\")\n\n# Load libraries\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(dplyr)\nlibrary(caret)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(ggforce)\nlibrary(pls)\nlibrary(mixOmics)"
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html#part-1-data-preparation-and-exploration",
    "href": "topics/hyperspectral_tutorial.html#part-1-data-preparation-and-exploration",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "3 Part 1: Data Preparation and Exploration",
    "text": "3 Part 1: Data Preparation and Exploration\n\n3.1 Loading and Inspecting the Data\nFirst, we load our hyperspectral dataset and examine its structure:\n\n# Load the hyperspectral data\ndata &lt;- read.csv(\"SamplesForWorkshop.csv\")\n\n# Inspect the basic structure\nhead(data[,1:21])\n\n  Month     Group SampleN Class       Chla       Chlb          C    Antho\n1 March Deciduous     101   SP1 0.04112532 0.01990401 0.02018104 0.001240\n2 March Deciduous     103   SP1 0.03786589 0.01835909 0.01925522 0.000829\n3 March Deciduous     106   SP1 0.06864117 0.03369560 0.02865739 0.000932\n4 March Deciduous     107   SP1 0.09533804 0.04758828 0.04024224 0.000903\n5 March Deciduous     108   SP1 0.05198037 0.02378042 0.02842488 0.000441\n6 March Deciduous     109   SP1 0.03009055 0.01016909 0.01941967 0.000037\n   Cellulose     Wax       X400       X401       X402       X403       X404\n1         NA      NA 0.01935004 0.01953985 0.01971527 0.01990466 0.02013160\n2 0.02858881 0.00138 0.02714292 0.02732804 0.02751218 0.02771258 0.02794536\n3         NA      NA 0.03921675 0.03947513 0.03973155 0.04001420 0.04034739\n4 0.02790119 0.00132 0.07315494 0.07358253 0.07399735 0.07442525 0.07488811\n5 0.02567766 0.00159 0.04725425 0.04754305 0.04782556 0.04812899 0.04847630\n6         NA      NA 0.12793647 0.12843469 0.12890088 0.12936994 0.12988197\n        X405       X406       X407       X408       X409       X410\n1 0.02035488 0.02059546 0.02085226 0.02109311 0.02135383 0.02163444\n2 0.02818707 0.02844890 0.02872564 0.02899116 0.02927687 0.02958125\n3 0.04068215 0.04104167 0.04142650 0.04180553 0.04220256 0.04262228\n4 0.07534337 0.07581604 0.07630594 0.07677775 0.07726508 0.07776967\n5 0.04883025 0.04920400 0.04959861 0.04999560 0.05041397 0.05085308\n6 0.13043007 0.13095214 0.13144691 0.13196342 0.13249848 0.13304018\n\n\n\n\n\n\n\n\nNoteDataset Structure\n\n\n\nThe dataset contains:\n\nMonth: Sampling time (March, July)\nGroup: Plant functional groups (Deciduous, Evergreen)\n\nClass: Plant species (SP0, SP1, SP2)\nBiomarkers: Chemical measurements in leaves: Chlorophylus A, Chlorophylus B, Carotenoids, Anthocyanins, Cellulose, Wax)\nSpectral bands: Reflectance values at different wavelengths (X400, X401, …, X2400)\n\nFor more details about the dataset, including measurement units, see Kozhoridze et al. (2016).\n\n\n\n\n3.2 Data Type Conversion\nNext, we convert categorical variables to factors and identify spectral columns:\n\n# Convert categorical variables to factors\ndata$Month &lt;- factor(data$Month, levels = c(\"March\", \"July\"))\ndata$Group &lt;- as.factor(data$Group)\ndata$Class &lt;- as.factor(data$Class)\n\n# Identify spectral band columns (wavelengths from 400-2400 nm)\nspectral_cols &lt;- colnames(data)[grepl(\"^X\\\\d+$\", colnames(data))]\ncat(\"Number of spectral band columns found:\", length(spectral_cols), \"\\n\")\n\nNumber of spectral band columns found: 1753 \n\n\n\n\n\n\n\n\nImportantWhy Factor Conversion Matters\n\n\n\nConverting to factors ensures proper statistical analysis and visualization. The spectral columns represent reflectance measurements at specific wavelengths, forming the hyperspectral signature of each sample.\n\n\n\n\n3.3 Creating Long Format for Analysis\nTransform the wide spectral data into long format for easier plotting and analysis:\n\n# Reshape spectral data to long format\ndata_long &lt;- data %&gt;%\n  pivot_longer(cols = all_of(spectral_cols), \n               names_to = \"Wavelength\", \n               values_to = \"Reflectance\") %&gt;%\n  mutate(Wavelength = as.numeric(sub(\"X\", \"\", Wavelength)))\n\n# Check the data structure\nprint(table(data$Class, data$Group, data$Month))\n\n, ,  = March\n\n     \n      Deciduous Evergreen\n  SP0         0         6\n  SP1         6         0\n  SP2         3         0\n\n, ,  = July\n\n     \n      Deciduous Evergreen\n  SP0         0         6\n  SP1         6         0\n  SP2         3         0"
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html#part-2-biomarker-analysis-and-visualization",
    "href": "topics/hyperspectral_tutorial.html#part-2-biomarker-analysis-and-visualization",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "4 Part 2: Biomarker Analysis and Visualization",
    "text": "4 Part 2: Biomarker Analysis and Visualization\n\n4.1 Comparing Biomarkers Across Groups\nCreate comprehensive visualizations to compare biomarker levels across different plant species and traits:\n\n# Prepare data for biomarker comparison\ndf_long &lt;- data %&gt;%\n  pivot_longer(cols = c(Chla, Chlb, C, Antho, Cellulose, Wax),\n               names_to = \"Biomarker\",\n               values_to = \"Value\")\n\n# Create boxplots comparing biomarkers\nggplot(df_long, aes(x = Group, y = Value, fill = Class)) +\n  geom_boxplot() +\n  facet_grid(Biomarker ~ Month, scales = \"free_y\") +\n  labs(title = \"Comparison of Biomarkers by Group and Class\",\n       y = \"Value\", x = \"Group\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\nComparison of biomarkers by group, class, and month\n\n\n\n\n\n\n\n\n\n\nTipUnderstanding Biomarkers\n\n\n\nEach biomarker represents different plant physiological processes:\n\nChla/Chlb: Chlorophyll content (photosynthetic capacity)\nC: Carotenoid content (accessory pigments for light harvesting and photoprotection)\nAntho: Anthocyanin content (stress response pigments)\nCellulose: Structural carbohydrates\nWax: Protective leaf surface compounds\n\n\n\n\n\n4.2 Statistical Testing\nPerform pairwise comparisons to identify significant differences:\n\n# Calculate pairwise comparisons for each month and biomarker\nvalid_comparisons &lt;- df_long %&gt;%\n  group_by(Month, Biomarker) %&gt;%\n  filter(!is.na(Value)) %&gt;%\n  filter(Class %in% c(\"SP0\", \"SP1\", \"SP2\")) %&gt;%\n  compare_means(formula = Value ~ Class,\n                group.by = c(\"Month\", \"Biomarker\"),\n                method = \"t.test\",\n                p.adjust.method = \"none\",\n                comparisons = list(c(\"SP0\", \"SP1\"), c(\"SP0\", \"SP2\"), c(\"SP1\", \"SP2\")),\n                na.rm = TRUE)\n\n# Add position information for significance bars\nglobal_max_y &lt;- max(df_long$Value, na.rm = TRUE)\nvalid_comparisons &lt;- valid_comparisons %&gt;%\n  group_by(Month, Biomarker) %&gt;%\n  arrange(p) %&gt;%\n  mutate(y.position = global_max_y * 1.05 + (row_number() - 1) * global_max_y * 0.1) %&gt;%\n  ungroup()\n\n# Create plot with significance indicators\np &lt;- ggboxplot(df_long, x = \"Class\", y = \"Value\", fill = \"Class\",\n               facet.by = c(\"Month\", \"Biomarker\"),\n               short.panel.labs = TRUE,\n               add = \"jitter\",\n               palette = \"jco\") +\n  stat_pvalue_manual(valid_comparisons,\n                     label = \"p.signif\",\n                     y.position = \"y.position\",\n                     tip.length = 0.01) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nprint(p)\n\n\n\n\nBiomarker comparisons with significance testing\n\n\n\n\n\n\n\n\n\n\nNoteStatistical Significance\n\n\n\nStatistical testing helps identify which differences are statistically significant rather than due to random variation. The significance indicators (, , ) show the strength of evidence against the null hypothesis."
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html#part-3-spectral-analysis-by-biomarker-levels",
    "href": "topics/hyperspectral_tutorial.html#part-3-spectral-analysis-by-biomarker-levels",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "5 Part 3: Spectral Analysis by Biomarker Levels",
    "text": "5 Part 3: Spectral Analysis by Biomarker Levels\nThis section explores how spectral signatures relate to biomarker concentrations.\n\n5.1 Creating High/Low Groups Based on Quantiles\n\n\n\n\n\n\nNoteQuantile-Based Biomarker Grouping\n\n\n\nTo identify samples with distinctly high versus low biomarker concentrations, we use the 75th percentile (third quartile) as a threshold within each sampling month. Samples with biomarker values at or above the 75th percentile are classified as “High” (representing the top 25% of samples), while all remaining samples are classified as “Low” (bottom 75%). This approach ensures we’re comparing the most extreme cases - plants with genuinely elevated biomarker levels against the majority with typical or lower concentrations - making spectral differences more pronounced and biologically meaningful.\n\n\nThe following function implements this quantile-based approach to analyze spectral differences between high and low biomarker groups:\n\nanalyze_spectral_by_biomarker &lt;- function(biomarker_name) {\n  # Filter data to specific plant groups\n  data1 &lt;- subset(data, Group == \"Deciduous\" | Group == \"Evergreen\")\n  data1 &lt;- data1 %&gt;%\n    mutate(Class = as.character(Class),\n           Class = str_trim(Class)) %&gt;%\n    filter(!is.na(.data[[biomarker_name]]))\n  \n  # Group samples by 3rd quantile (top 25% vs. bottom 75%)\n  data1 &lt;- data1 %&gt;%\n    group_by(Month) %&gt;%\n    mutate(q3_val = quantile(.data[[biomarker_name]], 0.75, na.rm = TRUE),\n           BioGroup = if_else(.data[[biomarker_name]] &gt;= q3_val, \"High\", \"Low\")) %&gt;%\n    ungroup()\n  \n  # Extract spectral columns\n  spectral_cols &lt;- colnames(data1)[str_detect(colnames(data1), \"^X\\\\d{3,4}$\")]\n  \n  # Reshape to long format\n  spectral_long &lt;- data1 %&gt;%\n    dplyr::select(Month, BioGroup, all_of(spectral_cols)) %&gt;%\n    pivot_longer(cols = all_of(spectral_cols), \n                 names_to = \"Wavelength\", \n                 values_to = \"Reflectance\") %&gt;%\n    mutate(Wavelength = as.numeric(str_remove(Wavelength, \"^X\"))) %&gt;%\n    filter(!is.na(Reflectance))\n  \n  # Filter to visible and near-infrared range\n  spectral_filtered &lt;- spectral_long %&gt;%\n    filter(Wavelength &gt;= 400, Wavelength &lt;= 2400)\n  \n  # Calculate mean reflectance for each group\n  avg_spectral &lt;- spectral_filtered %&gt;%\n    group_by(Month, BioGroup, Wavelength) %&gt;%\n    summarise(MeanReflectance = mean(Reflectance, na.rm = TRUE), .groups = \"drop\")\n  \n  # Create plot\n  ggplot(avg_spectral, aes(x = Wavelength, y = MeanReflectance, color = BioGroup)) +\n    geom_line(linewidth = 1) +\n    facet_wrap(~ Month) +\n    theme_minimal() +\n    labs(title = paste(\"Spectral Reflectance by\", biomarker_name, \"Level\"),\n         x = \"Wavelength (nm)\",\n         y = \"Mean Reflectance\",\n         color = paste(biomarker_name, \"Level\"))\n}\n\n\n\n5.2 Applying the Analysis to Different Biomarkers\n\n# Analyze different biomarkers\nbiomarkers &lt;- c(\"Antho\", \"C\", \"Chlb\", \"Chla\", \"Cellulose\", \"Wax\")\n\nfor(biomarker in biomarkers) {\n  plot &lt;- analyze_spectral_by_biomarker(biomarker)\n  print(plot)\n}\n\n\n\n\nSpectral signatures for different biomarker levels\n\n\n\n\n\n\n\nSpectral signatures for different biomarker levels\n\n\n\n\n\n\n\nSpectral signatures for different biomarker levels\n\n\n\n\n\n\n\nSpectral signatures for different biomarker levels\n\n\n\n\n\n\n\nSpectral signatures for different biomarker levels\n\n\n\n\n\n\n\nSpectral signatures for different biomarker levels\n\n\n\n\n\n\n\n\n\n\nTipUnderstanding Spectral Signatures\n\n\n\nDifferent biomarkers create distinct spectral patterns:\n\nChlorophyll: Strong absorption around 680 nm (red) and 430 nm (blue)\nCarotenoids: Absorption around 480 nm (blue) and 500-550 nm (green), with reflectance peak around 550 nm (yellow)\nAnthocyanins: Absorption in green-yellow region (500-600 nm)\nCellulose: Absorption features in near-infrared (1400-1500 nm, 1900-2000 nm)\nWax: Affects overall reflectance levels, especially in near-infrared"
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html#part-4-machine-learning-classification",
    "href": "topics/hyperspectral_tutorial.html#part-4-machine-learning-classification",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "6 Part 4: Machine Learning Classification",
    "text": "6 Part 4: Machine Learning Classification\n\n6.1 Classification Using Full Spectral Data\nWe’ll use Partial Least Squares Discriminant Analysis (PLS-DA) to classify plant samples based on their spectral signatures."
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html#what-is-pls-da",
    "href": "topics/hyperspectral_tutorial.html#what-is-pls-da",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "7 What is PLS-DA?",
    "text": "7 What is PLS-DA?\nPartial Least Squares Discriminant Analysis (PLS-DA) is a supervised classification technique that combines dimensionality reduction with discriminant analysis, making it particularly well-suited for high-dimensional data like hyperspectral datasets. Unlike traditional discriminant analysis methods that can fail when the number of variables exceeds the number of samples, PLS-DA first projects the data onto a lower-dimensional space of latent variables (components) that maximize the covariance between the predictor variables (spectral bands) and the class labels. This projection simultaneously reduces noise, handles multicollinearity among spectral bands, and identifies the most discriminative spectral features. The method then performs classification in this reduced space, making it robust for datasets with hundreds or thousands of correlated variables and relatively few samples - a common scenario in remote sensing applications."
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html#part-5-classification-using-vegetation-indices",
    "href": "topics/hyperspectral_tutorial.html#part-5-classification-using-vegetation-indices",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "8 Part 5: Classification Using Vegetation Indices",
    "text": "8 Part 5: Classification Using Vegetation Indices\nInstead of using all spectral bands, we can create vegetation indices that capture specific plant properties.\n\n8.1 Calculating Vegetation Indices\n\n# Define wavelength ranges for index calculations\ncols_750_770 &lt;- paste0(\"X\", 750:770)\ncols_490_500 &lt;- paste0(\"X\", 490:500)\ncols_660_690 &lt;- paste0(\"X\", 660:690)\ncols_690_720 &lt;- paste0(\"X\", 690:720)\ncols_760_800 &lt;- paste0(\"X\", 760:800)\ncols_510_520 &lt;- paste0(\"X\", 510:520)\ncols_690_710 &lt;- paste0(\"X\", 690:710)\ncols_530_570 &lt;- paste0(\"X\", 540:560)\n\n# Calculate mean reflectance for each range\nmean_750_770 &lt;- rowMeans(data[, cols_750_770], na.rm = TRUE)\nmean_490_500 &lt;- rowMeans(data[, cols_490_500], na.rm = TRUE)\nmean_660_690 &lt;- rowMeans(data[, cols_660_690], na.rm = TRUE)\nmean_690_720 &lt;- rowMeans(data[, cols_690_720], na.rm = TRUE)\nmean_760_800 &lt;- rowMeans(data[, cols_760_800], na.rm = TRUE)\nmean_510_520 &lt;- rowMeans(data[, cols_510_520], na.rm = TRUE)\nmean_690_710 &lt;- rowMeans(data[, cols_690_710], na.rm = TRUE)\nmean_530_570 &lt;- rowMeans(data[, cols_530_570], na.rm = TRUE)\n\n# Calculate vegetation indices\nVI_Chl &lt;- (1/mean_690_720 - 1/mean_760_800) * mean_760_800      # Chlorophyll index\nVI_C &lt;- (1/mean_510_520 - 1/mean_690_710) * mean_760_800        # Carbon index\nVI_Antho &lt;- (1/mean_530_570 - 1/mean_690_710) * mean_760_800    # Anthocyanin index\nVI_Cell &lt;- with(data, 100 * (0.5 * (X2030 + X2210) - X2100))   # Cellulose index\nVI_Wax &lt;- 1 / sqrt(mean_750_770 - mean_490_500 - mean_660_690)  # Wax index\n\n# Add indices to dataset\ndata$VI_Chl &lt;- VI_Chl\ndata$VI_C &lt;- VI_C\ndata$VI_Antho &lt;- VI_Antho\ndata$VI_Cell &lt;- VI_Cell\ndata$VI_Wax &lt;- VI_Wax\n\n\n\n\n\n\n\nTipWhy Use Vegetation Indices\n\n\n\nThese indices are designed to enhance specific plant properties while reducing the effects of:\n\nAtmospheric conditions\nSoil background\nIllumination variations\nNoise in individual spectral bands\n\n\n\n\n\n8.2 Classification Using Indices\n\n# Prepare index-based classification data\nClassData &lt;- subset(data, select = c(\"Month\", \"Group\", \"Class\", \n                                    \"VI_Chl\", \"VI_C\", \"VI_Antho\", \"VI_Cell\", \"VI_Wax\"))\n\n# Scale indices separately for each month\nMarchData &lt;- scale(ClassData[1:15, 4:8])\nJulyData &lt;- scale(ClassData[16:30, 4:8])\nClass_Data_Scaled &lt;- rbind(MarchData, JulyData)\nClass_Data_Scaled &lt;- cbind(ClassData[, 1:3], Class_Data_Scaled)\n\n# Modified PLS-DA function for vegetation indices\nrun_plsda_for_month_indices &lt;- function(data, month) {\n  df &lt;- subset(data, Month == month)\n  df &lt;- df[, !duplicated(names(df))]\n  \n  vi_cols &lt;- grep(\"^VI_\", names(df))\n  X &lt;- as.matrix(df[, vi_cols])\n  Y &lt;- factor(df$Class)\n  \n  plsda_model &lt;- plsda(X, Y, ncomp = 3)\n  \n  pred_out &lt;- predict(plsda_model, X)\n  pred &lt;- if (is.list(pred_out) && \"class\" %in% names(pred_out)) {\n    pred_out$class$max.dist[, 2]\n  } else {\n    as.factor(pred_out)\n  }\n  \n  cm &lt;- confusionMatrix(factor(pred, levels = levels(Y)), Y)\n  OA &lt;- cm$overall[\"Accuracy\"]\n  Kappa &lt;- cm$overall[\"Kappa\"]\n  \n  scores_all &lt;- plsda_model$variates$X[, 1:2]\n  plot_df &lt;- data.frame(scores_all, Class = Y)\n  colnames(plot_df)[1:2] &lt;- c(\"Comp.1\", \"Comp.2\")\n  \n  p &lt;- ggplot(plot_df, aes(x = Comp.1, y = Comp.2, color = Class)) +\n    geom_point(size = 3) +\n    geom_mark_ellipse(aes(fill = Class), alpha = 0.2, show.legend = FALSE) +\n    theme_minimal() +\n    ggtitle(sprintf(\"%s - OA=%.3f, Kappa=%.3f\", month, OA, Kappa)) +\n    theme(plot.title = element_text(hjust = 0.5))\n  \n  return(list(plot = p, OA = OA, Kappa = Kappa))\n}\n\n# Run classification with indices\nClass_Data_Scaled_M &lt;- subset(Class_Data_Scaled, Month == \"March\")\nClass_Data_Scaled_J &lt;- subset(Class_Data_Scaled, Month == \"July\")\n\nmarch_res &lt;- run_plsda_for_month_indices(Class_Data_Scaled_M, \"March\")\njuly_res &lt;- run_plsda_for_month_indices(Class_Data_Scaled_J, \"July\")\n\ncombined_plot &lt;- march_res$plot + july_res$plot + plot_layout(ncol = 2)\nprint(combined_plot)\n\n\n\n\nPLS-DA classification results using vegetation indices\n\n\n\n\n\n\n8.3 VIP Analysis for Vegetation Indices\n\n# VIP analysis for vegetation indices\nrun_plsda_and_get_vip_indices &lt;- function(data, month, ncomp = 3) {\n  df &lt;- subset(data, Month == month)\n  df &lt;- df[, !duplicated(names(df))]\n  \n  vi_cols &lt;- grep(\"^VI_\", names(df))\n  X &lt;- as.matrix(df[, vi_cols])\n  Y &lt;- factor(df$Class)\n  \n  plsda_model &lt;- mixOmics::plsda(X, Y, ncomp = ncomp)\n  vip_scores &lt;- mixOmics::vip(plsda_model)[,1]\n  \n  return(list(model = plsda_model, VIP = vip_scores))\n}\n\n# Extract VIP scores\nmarch_VIP &lt;- run_plsda_and_get_vip_indices(Class_Data_Scaled_M, \"March\")\njuly_VIP &lt;- run_plsda_and_get_vip_indices(Class_Data_Scaled_J, \"July\")\n\n# Prepare and plot VIP data\nvip_df &lt;- data.frame(\n  Variable = names(march_VIP$VIP),\n  March = as.numeric(march_VIP$VIP),\n  July = as.numeric(july_VIP$VIP)\n)\n\nvip_long &lt;- vip_df %&gt;%\n  pivot_longer(cols = c(\"March\", \"July\"), names_to = \"Month\", values_to = \"VIP\")\n\nvip_plot &lt;- ggplot(vip_long, aes(x = Variable, y = VIP, fill = Month)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8), width = 0.7) +\n  geom_hline(yintercept = 1, linetype = \"dashed\", color = \"red\") +\n  geom_text(aes(label = round(VIP, 2)), position = position_dodge(width = 0.8), \n            vjust = -0.5, size = 3) +\n  theme_minimal() +\n  labs(title = \"VIP Scores Comparison: March vs July (Vegetation Indices)\", \n       y = \"VIP Score\", x = NULL, fill = \"Month\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nprint(vip_plot)\n\n\n\n\nVIP scores for vegetation indices"
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html#summary-and-key-takeaways",
    "href": "topics/hyperspectral_tutorial.html#summary-and-key-takeaways",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "9 Summary and Key Takeaways",
    "text": "9 Summary and Key Takeaways\n\nData PreprocessingExploratory AnalysisClassification ApproachesModel ValidationBest Practices\n\n\n\nAlways scale spectral data before analysis\nHandle missing values appropriately\nConvert categorical variables to factors\nConsider temporal effects when designing analysis\n\n\n\n\nVisualize biomarker distributions across groups\nExamine spectral signatures for different conditions\nUse statistical tests to identify significant differences\nLook for patterns across different wavelength regions\n\n\n\nFull spectral data: - Pros: More information, captures subtle spectral features - Cons: High dimensionality, potential overfitting, computational complexity\nVegetation indices:\n- Pros: Reduced dimensionality, interpretable, robust to noise - Cons: May lose some spectral information, limited to pre-defined indices\n\n\n\nUse appropriate cross-validation strategies\nReport multiple accuracy metrics (OA, Kappa)\nInterpret VIP scores to understand important features\nConsider seasonal/temporal variations in model performance\n\n\n\n\nAlways validate results across different time periods\nConsider biological relevance when interpreting results\nUse multiple approaches to confirm findings\nDocument preprocessing steps for reproducibility"
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html#advanced-topics-and-extensions",
    "href": "topics/hyperspectral_tutorial.html#advanced-topics-and-extensions",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "10 Advanced Topics and Extensions",
    "text": "10 Advanced Topics and Extensions\n\n10.1 Cross-Validation Strategies\nFor more robust model evaluation, implement proper cross-validation:\n\n# Example of k-fold cross-validation for PLS-DA\nperform_cv_plsda &lt;- function(data, k_folds = 5) {\n  # Prepare data\n  ind_cols &lt;- grep(\"VI\", names(data))\n  X &lt;- as.matrix(data[, ind_cols])\n  Y &lt;- factor(data$Class)\n  \n  # Create folds\n  folds &lt;- createFolds(Y, k = k_folds, list = TRUE)\n  \n  cv_results &lt;- map_dfr(names(folds), function(fold_name) {\n    test_idx &lt;- folds[[fold_name]]\n    train_idx &lt;- setdiff(1:nrow(X), test_idx)\n    \n    # Train model\n    plsda_model &lt;- plsda(X[train_idx, ], Y[train_idx], ncomp = 3)\n    \n    # Predict on test set\n    pred &lt;- predict(plsda_model, X[test_idx, ])\n    pred_class &lt;- pred$class$max.dist[, 2]  # Use component 2\n    \n    # Calculate metrics\n    cm &lt;- confusionMatrix(factor(pred_class, levels = levels(Y)), Y[test_idx])\n    \n    tibble(\n      fold = fold_name,\n      accuracy = cm$overall[\"Accuracy\"],\n      kappa = cm$overall[\"Kappa\"]\n    )\n  })\n  \n  return(cv_results)\n}\n\n# Example usage (uncomment to run)\nmarch_data &lt;- subset(Class_Data_Scaled, Month == \"March\")\ncv_results &lt;- perform_cv_plsda(march_data)\nprint(paste(\"Mean CV Accuracy:\", round(mean(cv_results$accuracy), 3)))\n\n[1] \"Mean CV Accuracy: 0.517\""
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html#why-cross-validation-matters",
    "href": "topics/hyperspectral_tutorial.html#why-cross-validation-matters",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "11 Why Cross-Validation Matters",
    "text": "11 Why Cross-Validation Matters\nCross-validation prevents overly optimistic performance estimates by testing models on data they haven’t seen during training. The earlier classification results used the same data for both training and testing (self-prediction), which typically inflates accuracy metrics since models can memorize training patterns rather than learn generalizable features. K-fold cross-validation splits data into multiple train-test partitions, providing more realistic estimates of how well the model will perform on new, unseen samples - the true test of a classification algorithm’s practical utility."
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html#conclusion",
    "href": "topics/hyperspectral_tutorial.html#conclusion",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "12 Conclusion",
    "text": "12 Conclusion\nThis tutorial provides a comprehensive workflow for analyzing hyperspectral data in plant science applications. The methods demonstrated here can be adapted to various remote sensing and precision agriculture applications. The combination of statistical analysis, machine learning, and domain knowledge creates a robust framework for understanding plant spectral properties and their relationship to physiological characteristics.\nThe integration of multiple analytical approaches—from basic statistical comparisons to advanced machine learning techniques—provides researchers with a complete toolkit for hyperspectral data analysis. The emphasis on both full spectral analysis and vegetation indices demonstrates the trade-offs between detailed spectral information and practical, interpretable measures.\n\n\n\n\n\n\nNoteNext Steps\n\n\n\nTo further develop your hyperspectral analysis skills:\n\nCross-validation: Implement robust validation strategies with your own datasets\nAlternative algorithms: Experiment with Random Forest, SVM, or deep learning approaches\nFeature selection: Apply dimensionality reduction techniques to optimize model performance\nTemporal analysis: Explore how spectral signatures change over time or growing seasons\nScale integration: Connect lab measurements to field and satellite observations\nOperational applications: Develop automated pipelines for routine monitoring tasks\n\n\n13 Additional Resources\n\nSpectral libraries: USGS, ECOSIS for reference spectra\nSoftware packages: hsdar, RStoolbox for specialized hyperspectral analysis\nRemote sensing: Integration with Google Earth Engine or other platforms\nField validation: Best practices for ground-truthing remote sensing predictions\n\n\n\n\n\n\n\n\n\n\nWarningImportant Considerations\n\n\n\nWhen applying these methods to your own data:\n\nSample size: Ensure adequate samples per class for reliable statistics\nData quality: Check for instrument calibration and atmospheric corrections\nBiological relevance: Validate that spectral differences align with known plant physiology\n\nTemporal effects: Account for seasonal, phenological, and environmental variations\nScale effects: Consider how lab results translate to field and landscape scales\nModel generalization: Test models across different sites, sensors, and conditions\n\n\n\n\nThis tutorial was designed to provide both theoretical understanding and practical implementation guidance for hyperspectral data analysis. The modular structure allows researchers to adapt specific components to their unique research questions and datasets."
  },
  {
    "objectID": "topics/hyperspectral_tutorial.html#additional-resources",
    "href": "topics/hyperspectral_tutorial.html#additional-resources",
    "title": "Hyperspectral Data Analysis Tutorial: From Spectral Reflectance to Plant Classification",
    "section": "13 Additional Resources",
    "text": "13 Additional Resources\n\nSpectral libraries: USGS, ECOSIS for reference spectra\nSoftware packages: hsdar, RStoolbox for specialized hyperspectral analysis\nRemote sensing: Integration with Google Earth Engine or other platforms\nField validation: Best practices for ground-truthing remote sensing predictions"
  },
  {
    "objectID": "topics/hyperspectral_intro.html",
    "href": "topics/hyperspectral_intro.html",
    "title": "Hyperspectral Data Analysis: An Introduction",
    "section": "",
    "text": "Remote sensing reveals the invisible language of plants through their interaction with light. While our eyes perceive only three broad color channels, hyperspectral sensors measure reflectance across hundreds of narrow wavelength bands from 400 to 2400 nm, creating unique spectral signatures that encode information about plant biochemistry and physiology.\nThe Color-Chemistry Connection\nEvery plant pigment and structural compound absorbs and reflects light at specific wavelengths, creating diagnostic spectral patterns. Chlorophylls dominate healthy green vegetation with strong absorption around 680 nm (red) and 430 nm (blue), while carotenoids absorb in the blue-green region (480-560 nm). Anthocyanins, stress-response pigments that accumulate during senescence or environmental stress, create characteristic absorption patterns in the green-yellow region (500-600 nm). Even structural components like leaf waxes and cellulose leave distinct spectral fingerprints in the near-infrared and shortwave infrared regions.\nFrom Spectral Signatures to Biological Insights\nThese spectral patterns change dynamically across seasons and in response to stress. As leaves transition from spring flush through summer maturity to autumn senescence, their reflectance spectra transform, revealing shifts in pigment composition, water content, and structural integrity. By measuring these spectral changes, we can track plant phenology, detect stress before visible symptoms appear, and estimate biochemical concentrations non-destructively from leaf to landscape scales.\nThe Analysis Challenge\nThe richness of hyperspectral data—hundreds of correlated wavelength measurements per sample—creates both opportunity and challenge. This tutorial demonstrates how to extract meaningful biological information from high-dimensional spectral data using statistical analysis, vegetation indices, and machine learning classification techniques, bridging the gap between raw reflectance measurements and actionable ecological understanding."
  },
  {
    "objectID": "topics/hyperspectral_intro.html#introduction-to-hyperspectral-remote-sensing-of-plant-functional-traits",
    "href": "topics/hyperspectral_intro.html#introduction-to-hyperspectral-remote-sensing-of-plant-functional-traits",
    "title": "Hyperspectral Data Analysis: An Introduction",
    "section": "",
    "text": "Remote sensing reveals the invisible language of plants through their interaction with light. While our eyes perceive only three broad color channels, hyperspectral sensors measure reflectance across hundreds of narrow wavelength bands from 400 to 2400 nm, creating unique spectral signatures that encode information about plant biochemistry and physiology.\nThe Color-Chemistry Connection\nEvery plant pigment and structural compound absorbs and reflects light at specific wavelengths, creating diagnostic spectral patterns. Chlorophylls dominate healthy green vegetation with strong absorption around 680 nm (red) and 430 nm (blue), while carotenoids absorb in the blue-green region (480-560 nm). Anthocyanins, stress-response pigments that accumulate during senescence or environmental stress, create characteristic absorption patterns in the green-yellow region (500-600 nm). Even structural components like leaf waxes and cellulose leave distinct spectral fingerprints in the near-infrared and shortwave infrared regions.\nFrom Spectral Signatures to Biological Insights\nThese spectral patterns change dynamically across seasons and in response to stress. As leaves transition from spring flush through summer maturity to autumn senescence, their reflectance spectra transform, revealing shifts in pigment composition, water content, and structural integrity. By measuring these spectral changes, we can track plant phenology, detect stress before visible symptoms appear, and estimate biochemical concentrations non-destructively from leaf to landscape scales.\nThe Analysis Challenge\nThe richness of hyperspectral data—hundreds of correlated wavelength measurements per sample—creates both opportunity and challenge. This tutorial demonstrates how to extract meaningful biological information from high-dimensional spectral data using statistical analysis, vegetation indices, and machine learning classification techniques, bridging the gap between raw reflectance measurements and actionable ecological understanding."
  },
  {
    "objectID": "topics/hyperspectral_intro.html#where-to-go-further",
    "href": "topics/hyperspectral_intro.html#where-to-go-further",
    "title": "Hyperspectral Data Analysis: An Introduction",
    "section": "Where to go further?",
    "text": "Where to go further?\nWatch the video lecture in which Dr. Giorgi Kozhoridze introduces the key concepts for this lesson:\n\nView and download the presentation from the video:\n\nRead the theory\nAnalyze real data with a practical tutorial in R"
  },
  {
    "objectID": "topics/DART_theory.html",
    "href": "topics/DART_theory.html",
    "title": "Theoretical Background: Radiative Transfer Modelling for Ecosystem Monitoring",
    "section": "",
    "text": "Remote sensing provides us with unprecedented capabilities to observe Earth’s ecosystems from above. However, the spectral signals captured by satellite and airborne sensors represent complex interactions between electromagnetic radiation and vegetation structures. To unlock the full information content of these signals, we need more than statistical relationships—we need physical understanding of how light interacts with plant canopies.\nRadiative Transfer Models (RTMs) are powerful tools that use physical equations to simulate light interaction within virtual scenes, including forests, agricultural fields, and urban environments (Gastellu-Etchegorry et al. 2017). Unlike empirical models that rely on correlations between spectral data and field measurements, RTMs are based on the fundamental laws of physics governing light propagation, scattering, and absorption (Knyazikhin et al. 1998). This physical foundation makes RTMs invaluable for:\n\nInterpreting remote sensing observations by linking canopy reflectance to biophysical and biochemical properties\nUnderstanding ecosystem processes related to light scattering and energy balance\nDesigning new sensors and optimizing acquisition strategies\nRetrieving vegetation traits that cannot be directly measured from space\n\nThe evolution from simple 1D turbid medium approximations to complex 3D ray-tracing models has paralleled advances in computational power and our understanding of canopy architecture (Widlowski et al. 2015). Today’s RTMs can simulate scenes with remarkable detail, from individual leaf biochemistry to landscape-scale heterogeneity."
  },
  {
    "objectID": "topics/DART_theory.html#introduction-the-power-of-physical-modelling",
    "href": "topics/DART_theory.html#introduction-the-power-of-physical-modelling",
    "title": "Theoretical Background: Radiative Transfer Modelling for Ecosystem Monitoring",
    "section": "",
    "text": "Remote sensing provides us with unprecedented capabilities to observe Earth’s ecosystems from above. However, the spectral signals captured by satellite and airborne sensors represent complex interactions between electromagnetic radiation and vegetation structures. To unlock the full information content of these signals, we need more than statistical relationships—we need physical understanding of how light interacts with plant canopies.\nRadiative Transfer Models (RTMs) are powerful tools that use physical equations to simulate light interaction within virtual scenes, including forests, agricultural fields, and urban environments (Gastellu-Etchegorry et al. 2017). Unlike empirical models that rely on correlations between spectral data and field measurements, RTMs are based on the fundamental laws of physics governing light propagation, scattering, and absorption (Knyazikhin et al. 1998). This physical foundation makes RTMs invaluable for:\n\nInterpreting remote sensing observations by linking canopy reflectance to biophysical and biochemical properties\nUnderstanding ecosystem processes related to light scattering and energy balance\nDesigning new sensors and optimizing acquisition strategies\nRetrieving vegetation traits that cannot be directly measured from space\n\nThe evolution from simple 1D turbid medium approximations to complex 3D ray-tracing models has paralleled advances in computational power and our understanding of canopy architecture (Widlowski et al. 2015). Today’s RTMs can simulate scenes with remarkable detail, from individual leaf biochemistry to landscape-scale heterogeneity."
  },
  {
    "objectID": "topics/DART_theory.html#types-of-radiative-transfer-models",
    "href": "topics/DART_theory.html#types-of-radiative-transfer-models",
    "title": "Theoretical Background: Radiative Transfer Modelling for Ecosystem Monitoring",
    "section": "2 Types of Radiative Transfer Models",
    "text": "2 Types of Radiative Transfer Models\nRTMs operate at different spatial scales and levels of complexity, each designed for specific applications and data types. Understanding this hierarchy is essential for selecting the appropriate model for a given research question.\n\n2.1 Leaf-Level RTMs\n\n\n\n\n\n\nFigure 1: Leaf-level radiative transfer mechanisms. (a) Light interaction with leaf structure: polarized (red) and non-polarized (black) light interact through surface reflection at micro-facets, absorption by chloroplasts, and scattering within mesophyll tissue. (b) Conceptual diagram showing light interaction with leaf surface and internal structures including epidermis, palisade, spongy mesophyll, and air spaces. (c) Simplified plate model showing light transmission and reflection through mesophyll layers with refractive index n&gt;1. (c) Detailed representation of light path including surface reflection and internal scattering at multiple interfaces. (d) Multi-layer representation with N layers showing transmittance (T_N) and reflectance (R_N) terms. Sources: (a) Li et al. (2025), (b) Xu and Ye (2023)\n\n\n\nLeaf-level RTMs simulate the optical properties of individual leaves based on their internal structure and biochemical composition (Jacquemoud and Baret 1990). Figure 1 illustrates the complex interactions of light within leaf tissues. Key components include:\nInternal Leaf Structure:\n\nUpper and lower epidermis: Protective layers with minimal pigment content\nPalisade mesophyll: Tightly packed cells containing high concentrations of chloroplasts\nSpongy mesophyll: Loosely arranged cells with air spaces creating scattering interfaces\nVascular tissues: Veins transporting water and nutrients\n\nLight Interaction Mechanisms:\nThe plate model (Figure 1 panels b-d) shows how light propagates through leaf layers. At each interface between materials with different refractive indices (typically air n=1 and cell wall material n≈1.4), light undergoes:\n\nSpecular reflection at the surface (~4% of incident light)\nRefraction into the leaf interior following Snell’s law\nAbsorption by pigments (chlorophylls, carotenoids, anthocyanins, water)\nScattering at cell walls and air-cell interfaces\nMultiple internal reflections within the mesophyll structure\n\nPROSPECT Model:\nThe most widely used leaf-level RTM is PROSPECT (Jacquemoud and Baret 1990; Féret et al. 2017), which treats the leaf as a stack of N identical layers, each characterized by a refractive index and specific absorption coefficients. The model requires as inputs:\n\nN: Leaf structure parameter (related to mesophyll thickness and compactness)\nC_ab: Chlorophyll a+b content (μg/cm²)\nC_ar: Carotenoid content (μg/cm²)\n\nC_brown: Brown pigments (arbitrary units)\nC_w: Equivalent water thickness (g/cm² or cm)\nC_m: Dry matter content (g/cm²)\nC_anth: Anthocyanin content (μg/cm²) [in PROSPECT-D and later versions]\n\nThe model outputs hemispherical reflectance and transmittance spectra (typically 400-2500 nm), which serve as inputs to canopy-level models.\n\n\n\n\n\n\nNotePROSPECT Model Evolution\n\n\n\nThe PROSPECT model has evolved through several versions:\n\nPROSPECT (1990): Original version with 4 parameters\nPROSPECT-5 (2008): Added brown pigments\nPROSPECT-D (2017): Added anthocyanins (Féret et al. 2017)\nPROSPECT-PRO (2021): Improved protein absorption features\n\nEach version improves spectral fidelity and retrieval accuracy for specific compounds.\n\n\n\n\n2.2 Canopy-Level RTMs\n\n\n\n\n\n\nFigure 2: Canopy-level radiative transfer in 3D scene. The diagram shows the DART model structure including atmosphere layers (high and mid atmosphere), Earth scene with detailed 3D vegetation (trees, grass, water, topography), and multiple sensor configurations. Key elements include: TOA (Top of Atmosphere), BOA (Bottom of Atmosphere), direct sun irradiance, atmosphere radiance, per-pixel radiation, and both satellite and airborne sensor geometries. Source: Gastellu-Etchegorry et al. (2017).\n\n\n\nCanopy-level RTMs simulate light interaction within entire plant canopies or landscape scenes (Gastellu-Etchegorry et al. 2017). Figure 2 illustrates the comprehensive approach of 3D canopy models like DART, which can represent:\nVertical Structure:\n\nAtmospheric layers: High and mid atmosphere with gas absorption, aerosol scattering\nCanopy layers: Vegetation at multiple heights with varying density\nUnderstory: Ground vegetation, leaf litter, soil\nUrban elements: Buildings, roads, other artificial structures when applicable\n\nHorizontal Heterogeneity:\n\nTree crowns: Individual trees with species-specific architecture\nCanopy gaps: Openings allowing direct sunlight to reach understory\nTopography: Terrain elevation affecting local illumination geometry\nMixed surfaces: Combination of vegetation, water, bare soil\n\nRadiation Components:\nCanopy-level RTMs must account for multiple radiation pathways:\n\nDirect solar radiation: Unscattered photons from the sun\nDiffuse sky radiance: Light scattered by atmosphere before reaching canopy\nMultiple scattering within canopy: Photons bouncing between leaves, stems, ground\nAtmospheric coupling: Light exiting canopy, being scattered by atmosphere, and potentially re-entering\nTopographic effects: Shadows, adjacency effects from nearby terrain\n\nModel Inputs:\nCanopy-level RTMs require comprehensive parameterization:\n\nOptical properties: Leaf/bark/soil reflectance and transmittance spectra\nStructural parameters: LAI (Leaf Area Index), canopy height, crown dimensions\n3D Architecture: Tree positions, sizes, shapes; or turbid medium descriptions\nEnvironmental conditions: Sun angles, atmospheric composition\nSensor geometry: View angles, spatial resolution, spectral bands\n\nModel Outputs:\nThese models generate various products:\n\nBidirectional Reflectance Factor (BRF): Directional reflectance images\nRadiative budget: Absorbed, transmitted, and reflected radiation\nLiDAR waveforms: Simulated laser scanning returns\nBrightness temperature: Thermal radiation (if thermal module enabled)\n\n\n\n2.3 Levels of Complexity\nRTMs can be categorized by their representation of canopy architecture (Bailey, Ponce de León, and Krayenhoff 2020):\n\n\n\n\n\n\nFigure 3: Three levels of canopy representation in radiative transfer models. Left: 1D turbid medium with horizontally homogeneous layers. Center: 3D geometrical objects with simple crown shapes. Right: 3D complex representation with explicit 3D tree structures. Yellow arrows indicate incident direct solar radiation, with scattered radiation paths shown by dashed lines.\n\n\n\n1D Models (Turbid Medium):\nThe simplest approach treats vegetation as horizontally infinite, vertically stratified layers with uniformly distributed scatterers (Figure 3, left panel). Examples include SAIL (Verhoef 1984) and GeoSAIL. Advantages:\n\nComputationally fast\nWell-suited for homogeneous canopies (crops, grasslands)\nMany analytical solutions available\n\nLimitations:\n\nCannot represent gaps, tree crowns, or horizontal heterogeneity\nPoor performance for forests and sparse vegetation\nNeglects directional structure effects\n\n3D Geometrical Models:\nAn intermediate approach represents trees as geometric primitives (cones, ellipsoids, cylinders) filled with turbid medium (Figure 3, center panel). Examples include FLIGHT (North 1996) and discrete models. Advantages:\n\nCaptures crown-scale structure and gaps\nMore realistic than 1D for forests\nModerate computational demands\n\nLimitations:\n\nStill simplified crown architecture\nCannot represent branch-level structure\nLess accurate for detailed structural studies\n\n3D Complex Models:\nThe most sophisticated approach explicitly represents 3D tree architecture using detailed geometric meshes or voxelized structures (Figure 3, right panel). Examples include DART-Lux (Gastellu-Etchegorry et al. 2017), LESS (Qi et al. 2019), and Helios++ (Bailey 2019). Advantages:\n\nHighest realism and accuracy\nCan incorporate terrestrial laser scanning (TLS) data\nSuitable for LiDAR simulation and fine-scale studies\n\nLimitations:\n\nComputationally intensive\nRequires detailed 3D vegetation data\nComplex parameterization\n\n\n\n\n\n\n\nImportantChoosing the Right Model\n\n\n\nModel selection depends on:\n\nApplication scale: Leaf, plot, landscape\nAvailable data: Biochemical measurements, structural data, TLS point clouds\nResearch questions: What traits need to be retrieved?\nComputational resources: Runtime and memory constraints\nEcosystem type: Homogeneous crops vs. heterogeneous forests\n\nFor high-resolution hyperspectral imagery of forests, 3D complex models offer the best performance."
  },
  {
    "objectID": "topics/DART_theory.html#radiative-transfer-model-products",
    "href": "topics/DART_theory.html#radiative-transfer-model-products",
    "title": "Theoretical Background: Radiative Transfer Modelling for Ecosystem Monitoring",
    "section": "3 Radiative Transfer Model Products",
    "text": "3 Radiative Transfer Model Products\nRTMs generate a variety of outputs useful for different remote sensing applications (Gastellu-Etchegorry et al. 2017):\n\n3.1 Optical Products\nBidirectional Reflectance Factor (BRF):\nThe most common output, BRF quantifies how reflectance varies with illumination and viewing geometry. It is defined as the ratio of reflected radiance in a given direction to the radiance that would be reflected by an ideal Lambertian surface under identical illumination (Schaepman et al. 2009):\n\\[\\text{BRF}(\\theta_s, \\phi_s, \\theta_v, \\phi_v, \\lambda) = \\frac{\\pi \\cdot L(\\theta_v, \\phi_v, \\lambda)}{E(\\theta_s, \\phi_s, \\lambda)}\\]\nwhere:\n\n\\(\\theta_s, \\phi_s\\): Solar zenith and azimuth angles\n\\(\\theta_v, \\phi_v\\): View zenith and azimuth angles\n\n\\(\\lambda\\): Wavelength\n\\(L\\): Reflected radiance\n\\(E\\): Incoming irradiance\n\n\n\n\n\n\n\nFigure 4: Multi-angle BRF patterns for a forest canopy. Polar plots showing BRF at four wavelengths (550 nm, 665 nm, 780 nm, 1650 nm) across viewing hemisphere. (a) Canopy simulation design. (b) BRF vs. viewing zenith angle for different solar positions (shown as colored lines). (c) Polar projections with solar position marked by star symbol. Patterns reveal strong forward scattering (hotspot) and angular anisotropy varying with wavelength. Source: Hanuš et al. (2023)\n\n\n\nFigure 4 illustrates how BRF varies with viewing geometry at different wavelengths. Key features include:\n\nHotspot: Peak reflectance when sun and sensor are aligned (zero phase angle)\nDarkspot: Minimum reflectance in backscattering direction (opposite sun)\nBowl shape: General decrease in reflectance with increasing view zenith angle\nSpectral dependence: Angular patterns differ between visible and NIR wavelengths\n\nRTMs can simulate BRF for any combination of sun-sensor geometries, enabling:\n\nBRDF normalization of multi-temporal imagery (Hanuš et al. 2023)\nAtmosphere-corrected reflectance estimation\nOptimal view angle selection for trait retrieval\n\n\n\n3.2 Thermal Products\nSome RTMs (e.g., DART) simulate brightness temperature by coupling radiative transfer with energy balance equations (Gastellu-Etchegorry et al. 2015). This enables:\n\nCanopy temperature mapping from thermal imagery\nEvapotranspiration estimation via surface energy balance\nWater stress detection using thermal-optical indices\n\n\n\n3.3 LiDAR Products\nAdvanced 3D RTMs can simulate laser scanning returns (Gastellu-Etchegorry et al. 2017), providing:\n\nAirborne LiDAR waveforms: Full-waveform returns at nadir or off-nadir angles\nTerrestrial Laser Scanning (TLS) point clouds: Ground-based returns from tree structure\nMobile LiDAR: Vehicle-mounted or handheld scanner simulations\n\nThese synthetic LiDAR data support:\n\nSensor design: Testing new LiDAR configurations before deployment\nAlgorithm development: Validating extraction methods for canopy height, LAI, biomass\nPoint cloud interpretation: Understanding how 3D structure affects returns\n\n\n\n3.4 Radiative Budget\nRTMs compute the absorption, transmission, and reflection of radiation throughout the canopy (Widlowski et al. 2015):\n\nAbsorbed PAR (Photosynthetically Active Radiation): Critical for photosynthesis models\nTransmitted radiation: Light reaching understory\nVertical profiles: Radiation availability at different canopy heights\nPer-triangle/voxel budget: Spatially explicit energy balance\n\nThese outputs link remote sensing to ecosystem functioning and carbon cycle models (Malenovský et al. 2013)."
  },
  {
    "objectID": "topics/DART_theory.html#applications-of-radiative-transfer-models",
    "href": "topics/DART_theory.html#applications-of-radiative-transfer-models",
    "title": "Theoretical Background: Radiative Transfer Modelling for Ecosystem Monitoring",
    "section": "4 Applications of Radiative Transfer Models",
    "text": "4 Applications of Radiative Transfer Models\nRTMs serve multiple roles in ecosystem science and remote sensing (Malenovský et al. 2021):\n\n4.1 1. BRDF/BRF Correction and Normalization\nMulti-temporal remote sensing imagery suffers from varying sun-sensor geometries that create artificial reflectance changes unrelated to vegetation state. RTMs enable physics-based corrections (Hanuš et al. 2023):\nProblem: Reflectance of the same surface can vary by 20-50% depending on viewing angle (Schaepman et al. 2009).\nSolution:\n\nSimulate BRF patterns for the actual scene using RTM\nNormalize observed reflectance to a standard geometry (e.g., nadir view, 45° solar zenith)\nApply corrections accounting for topography, adjacency effects\n\nBenefits:\n\nImproved phenology tracking\nBetter change detection\nEnhanced time-series analysis\n\n\n\n4.2 2. Biophysical and Biochemical Trait Retrieval\nThe primary application of RTMs is estimating vegetation properties from remote sensing spectra. This is typically accomplished through Look-Up Table (LUT) inversion (Dorigo et al. 2007):\nWorkflow:\n\nGenerate LUT: Run RTM thousands of times varying input traits (LAI, chlorophyll, etc.)\nCreate spectral database: Store simulated spectra with corresponding trait values\nMatch observations: Find LUT entry with spectrum closest to observed pixel\nRetrieve traits: Extract corresponding trait values\n\nRetrieved Traits Include:\n\nBiochemical: Chlorophyll (Cab), carotenoids (Car), water content (Cw), dry matter (Cm), anthocyanins (Canth)\nStructural: LAI, canopy height, canopy cover, clumping index\nPhotosynthetic: Absorbed PAR, light use efficiency\n\n\n\n\n\n\n\nFigure 5: Vegetation trait retrieval workflow. Left: True-color (CASI 2016) and false-color (SASI 2016) hyperspectral images of a forest study site. Right: Retrieved trait maps showing spatial distribution of leaf chlorophyll content (Cab), leaf carotenoids content (Car), leaf water content (Cw), and leave area index (LAI). Color scales indicate concentration gradients across the heterogeneous canopy. Source: Janoutová et al. (2021)\n\n\n\nFigure 5 demonstrates trait retrieval results from airborne hyperspectral imagery, showing detailed spatial patterns of biochemical content and canopy structure.\n\n\n4.3 3. Sensitivity Analysis\nBefore collecting expensive remote sensing data or designing retrieval algorithms, RTMs can reveal which spectral bands contain information about specific traits (Malenovský et al. 2021):\nApproach:\n\nVary one trait while holding others constant\nSimulate spectra for each trait value\nQuantify spectral sensitivity: \\(\\partial \\text{BRF}(\\lambda) / \\partial \\text{Trait}\\)\nIdentify optimal wavebands for trait estimation\n\n\n\n\n\n\n\nFigure 6: Sensitivity analysis for different tree types and canopy representations. Simulated RGB, CIR (Color Infrared), and 3D canopy views for three species (Norway spruce, white peppermint, European beech) using three modeling approaches: 3D detailed, turbid medium, and simple geometric representation. Each representation creates different spatial patterns and spectral responses, revealing the importance of architectural fidelity for accurate simulations. Source: Janoutová et al. (2021)\n\n\n\nFigure 6 illustrates how different levels of structural representation (3D detailed vs. turbid medium vs. simple geometry) affect simulated imagery. This type of analysis reveals:\n\nWhich traits are retrievable given sensor specifications\nHow structural simplifications affect spectral accuracy\nTrade-offs between model complexity and simulation quality\n\n\n\n4.4 4. Radiative Budget Modeling\nUnderstanding how much light is absorbed, transmitted, or reflected by vegetation is fundamental to ecosystem energy balance and photosynthesis (Malenovský et al. 2013):\nApplications:\n\nCarbon cycle modeling: Linking absorbed PAR to gross primary productivity\nEnergy balance studies: Partitioning radiation into sensible and latent heat fluxes\nVertical profile analysis: Light availability for understory species\nClimate model parameterization: Albedo and roughness for land surface schemes\n\n\n\n4.5 5. Sensor Simulation and Mission Design\nBefore launching new satellites or airborne campaigns, RTMs can test sensor configurations and optimize acquisition strategies:\nQuestions Addressed:\n\nWhat spatial resolution is needed to resolve canopy gaps?\nAre 10 nm bands better than 20 nm bands for chlorophyll retrieval?\nWhat view angles maximize sensitivity to LAI?\nHow does along-track vs. across-track scanning affect shadowing?\n\nCase Study: The FLEX (Fluorescence Explorer) satellite mission used RTM simulations extensively to define optimal spectral bands, view angles, and overpass times for measuring solar-induced chlorophyll fluorescence (Malenovský et al. 2021)."
  },
  {
    "objectID": "topics/DART_theory.html#the-radiation-transfer-model-intercomparison-rami-initiative",
    "href": "topics/DART_theory.html#the-radiation-transfer-model-intercomparison-rami-initiative",
    "title": "Theoretical Background: Radiative Transfer Modelling for Ecosystem Monitoring",
    "section": "5 The Radiation transfer Model Intercomparison (RAMI) Initiative",
    "text": "5 The Radiation transfer Model Intercomparison (RAMI) Initiative\nGiven the diversity of RTMs with different underlying assumptions and implementations, the community recognized the need for systematic model benchmarking. The RAMI initiative provides standardized test scenes and reference solutions (Widlowski et al. 2015).\n\n\n\n\n\n\nFigure 7: Evolution of the RAMI initiative from 1999 to 2022. Timeline showing progression through RAMI phases: RAMI-1 (1999) for basic benchmarking, RAMI-2 (2002) for expanded scenarios, RAMI-3 (2005) for 3D heterogeneous scenes, ROMC (2007) for online model checker, RAMI4PILPS (2008/2009) coupling with land surface models, RAMI-IV (2009/2015) for realistic forest scenes, RAMI-V (2020) for comprehensive validation, and RAMI4ATM (2022) for atmospheric coupling. Source: Source: https://rami-benchmark.jrc.ec.europa.eu/_www/index.php\n\n\n\nRAMI Objectives:\n\nIdentify model errors through systematic comparison\nProvide reference datasets for model validation\nEstablish best practices for model use\nBenchmark computational performance\n\nTest Scenarios:\n\nAbstract scenes: Homogeneous canopies, geometric primitives with known solutions\nRealistic scenes: Laser-scanned forests, heterogeneous landscapes\nMulti-scale challenges: Leaf-to-landscape scaling tests\n\nParticipating Models:\nOver 30 RTMs have participated in RAMI exercises, including DART, FLIGHT, FRT, RAYTRAN, Sprint, SCOPE, and librat. Results have driven substantial improvements in model accuracy and efficiency.\n\n\n\n\n\n\nNoteRAMI Best Practices\n\n\n\nRAMI exercises revealed common issues:\n\nInterpolation errors in tabulated optical properties\nInsufficient angular sampling for anisotropic scattering\nNumerical precision problems in multi-scattering calculations\nBoundary condition artifacts at scene edges\n\nModern models incorporate fixes for these issues, but users should remain aware of potential limitations."
  },
  {
    "objectID": "topics/DART_theory.html#the-dart-model-a-comprehensive-3d-rtm",
    "href": "topics/DART_theory.html#the-dart-model-a-comprehensive-3d-rtm",
    "title": "Theoretical Background: Radiative Transfer Modelling for Ecosystem Monitoring",
    "section": "6 The DART Model: A Comprehensive 3D RTM",
    "text": "6 The DART Model: A Comprehensive 3D RTM\nAmong canopy-level RTMs, DART (Discrete Anisotropic Radiative Transfer) stands out for its comprehensiveness, computational efficiency, and active development (Gastellu-Etchegorry et al. 2017).\n\n\n\n\n\n\nFigure 8: DART model architecture showing three computational modes. Left: DART-FT using adapted discrete ordinates with voxelized atmosphere and scene. Center: DART-RC using forward Monte Carlo ray tracing with photon tracking. Right: DART-Lux using bi-directional path tracing with explicit triangle meshes. All modes simulate optical, thermal, and LiDAR products for natural and urban landscapes. Source: DART User Manual - https://dart.omp.eu/Public/documentation/contenu/documentation/DART_User_Manual.pdf\n\n\n\n\n6.1 Key Features\n1. Multiple Computational Modes:\nDART offers three ray-tracing engines optimized for different applications (Figure 8):\n\nDART-FT (Flux Tracking): Discrete ordinates method, fast for large scenes, good for satellite simulations\nDART-RC (Ray Carlo): Forward Monte Carlo, accurate for complex geometry, suitable for airborne sensing\n\nDART-Lux: Bi-directional path tracing, highest accuracy for detailed 3D scenes, optimal for UAV/TLS simulation\n\n2. Comprehensive Product Suite:\n\nOptical: BRF at any wavelength, any view angle\nThermal: Brightness temperature accounting for 3D structure\nLiDAR: Full-waveform airborne, TLS, and mobile laser scanning\nRadiative budget: 3D voxel grid of absorbed/transmitted radiation\nFluorescence: Solar-induced chlorophyll fluorescence (SIF)\n\n3. Integrated Leaf Model:\nPROSPECT is built into DART, enabling seamless simulation from biochemical traits to canopy reflectance. Users can specify Cab, Car, Cw, etc., and DART automatically computes leaf optical properties.\n4. Atmosphere Modeling:\nDART couples canopy and atmosphere radiative transfer, simulating:\n\nGas absorption (H2O, O2, O3, CO2)\nAerosol scattering (multiple aerosol models)\nTop-of-atmosphere (TOA) and bottom-of-atmosphere (BOA) products\nAtmospheric correction via inversion\n\n5. Flexible Scene Construction:\nUsers can build scenes using:\n\n3D geometric objects: Import OBJ/PLY meshes from TLS, photogrammetry, or modeling software\nVoxel grids: Define LAI and optical properties per voxel\nTurbid medium: Quick parametric description for homogeneous stands\nMixed representations: Combine approaches (e.g., explicit crowns + turbid understory)\n\n\n\n6.2 DART Advantages and Limitations\n\nAdvantagesDisadvantages\n\n\nComprehensive Capabilities:\n\nSimulate almost any remote sensing scenario\nOptical, thermal, LiDAR in one framework\nNatural and urban landscapes\n\nComputational Efficiency:\n\nHighly optimized code (C++/CUDA)\nParallelized (multi-core CPU, GPU acceleration)\nLarge, detailed scenes feasible on desktop computers\n\nActive Development:\n\nRegular updates with new features\nOptimization ongoing\nResponsive development team\n\nValidated Accuracy:\n\nConsistently performs well in RAMI exercises\nPeer-reviewed and widely used in literature\n\nStrong Community Support:\n\nActive user forum\nComprehensive manual (600+ pages)\nRegular training workshops (2-3 per year)\nPrepared tutorials and example scenes\n\n\n\nSteep Learning Curve:\n\nComplex graphical interface with hundreds of parameters\nOverwhelming for new users\nRequires understanding of radiative transfer theory\n\nParameterization Challenges:\n\nRequires detailed input data (optical properties, structure)\nMany parameters create opportunity for errors\nSensitivity to some parameters not always intuitive\n\nComputational Demands:\n\nDespite optimization, complex 3D scenes still take hours\nLarge LUTs require significant storage and computation time\nGPU acceleration helps but not always available\n\nProduct Interpretation:\n\nRich output requires expertise to interpret correctly\nMultiple products can be confusing\nUnits, coordinate systems need attention\n\nSoftware Maturity:\n\nSome features still experimental\nOccasional bugs (though rapidly fixed)\nDocumentation sometimes lags new features\n\n\n\n\n\n\n\n\n\n\nTipGetting Started with DART\n\n\n\nFor newcomers to DART:\n\nStart Simple: Begin with abstract scenes (homogeneous canopy) before attempting complex forests\nUse Tutorials: Work through provided examples in the DART manual\nAttend Training: DART summer schools offer hands-on guidance\nEngage Community: Post questions on the forum—developers and experienced users respond quickly\nValidate Incrementally: Compare simulations with field measurements at each step\nLeverage Tools: Use DART’s built-in tools (database manager, 3D viewer, sequence launcher) to streamline workflows"
  },
  {
    "objectID": "topics/DART_theory.html#vegetation-traits-retrieval",
    "href": "topics/DART_theory.html#vegetation-traits-retrieval",
    "title": "Theoretical Background: Radiative Transfer Modelling for Ecosystem Monitoring",
    "section": "7 Vegetation Traits Retrieval",
    "text": "7 Vegetation Traits Retrieval\nThe primary application of RTMs in ecosystem monitoring is retrieving biophysical and biochemical traits from remote sensing imagery. Unlike empirical methods that rely on statistical correlations, RTM-based retrieval has a physical foundation, making it more robust across different ecosystems, sensors, and viewing conditions (Dorigo et al. 2007).\n\n7.1 Retrieval Workflow Overview\n\n\n\n\n\n\nFigure 9: Vegetation traits retrieval workflow. The process flows from bottom to top: (1) Leaf & canopy RT models are parameterized with ground measurements, (2) Radiative transfer simulations generate a database of spectral signatures for quantitative vegetation parameters (chlorophylls shown as example), (3) Retrieval algorithm compares this database with reflectance image data (after corrections), (4) Validation using ground measurements confirms accuracy. The workflow represents bottom-up scaling from leaf to canopy level. Source: Malenovskỳ et al. (2009)\n\n\n\nFigure 9 illustrates the complete RTM-based retrieval workflow (Malenovský et al. 2013). The process involves:\n\nParameterization: Field measurements provide inputs for leaf and canopy RT models\nDatabase generation: RTM simulations create a Look-Up Table (LUT) of spectra for different trait combinations\nImage matching: Retrieval algorithms compare observed spectra with the LUT database\nValidation: Retrieved traits are compared with independent field measurements\n\nThis approach enables quantitative trait estimation from spectral data, bridging the gap between remote sensing observations and ecosystem properties.\n\n\n7.2 Choosing the Right Approach\nBefore starting a retrieval study, several key questions determine the appropriate RTM complexity (Gastellu-Etchegorry et al. 2017):\nWhat type of remote sensing data will be analyzed?\n\nSensor platform: Satellite, airborne, or UAV\nData type: Reflectance (BRF), point cloud, thermal imagery\nResolution: Spatial (pixel size) and spectral (number/width of bands)\nEcosystem type: Forest, agricultural field, or urban area\n\nWhat traits need to be retrieved?\n\nBiochemical traits: Chlorophyll content, carotenoids, water content, dry matter\nStructural traits: LAI, canopy cover, tree height, crown dimensions\nOther properties: Absorbed PAR, biomass, species composition\n\nExample decision:\nFor high-resolution UAV hyperspectral imagery (5 cm pixels, 32-52 nm bands) over a forest site, with the goal of retrieving biochemical traits like chlorophyll and carotenoids:\n→ 3D complex RTM (like DART) is required\nThe fine spatial resolution captures individual tree crowns and intra-crown variation, requiring explicit 3D representation. The hyperspectral data contains detailed biochemical information that can be extracted through physics-based modeling.\n\n\n7.3 Field Data Collection\nAccurate RTM parameterization requires comprehensive field measurements (Janoutová et al. 2021):\n\n\n\n\n\n\nFigure 10: Field measurement equipment and spectral data. (a) Spectroradiometers with contact probe (bark), pistol grip (ground), and integrating sphere (leaves). (b) Example spectral reflectance and transmittance curves for leaves (green wavelengths show characteristic chlorophyll absorption), and reflectance spectra for twigs/bark (brown) and ground (dashed black). These field measurements provide the optical properties needed to parameterize RTMs.\n\n\n\nOptical Properties:\nMeasure reflectance and transmittance of all scene elements using spectroradiometers:\n\nLeaves: Integrating sphere for both reflectance and transmittance\nBark/trunks: Contact probe for reflectance\nGround: Pistol grip for soil/litter reflectance\n\nBiochemical Analysis:\nLaboratory measurements complement spectral data:\n\nChlorophyll content (a and b)\nCarotenoid content\nWater and dry matter content\nThese can be used directly in PROSPECT model or to validate leaf spectra\n\nStructural Parameters:\nDocument canopy architecture:\n\nLAI (Leaf Area Index) and canopy cover\nTree positions, heights, crown dimensions\nFor detailed studies: Terrestrial laser scanning (TLS) for 3D structure\n\nAlternative Data Sources:\nWhen field measurements are limited, use databases:\n\nTRY database for plant traits\nICP Forest, ICOS networks for forest plots\nPublished spectral libraries for common species\n\n\n\n7.4 Scene Configuration\nRTM simulations require careful scene parameterization. General parameters apply to all RTM studies (Gastellu-Etchegorry et al. 2017):\nSite Location and Sun Geometry:\n\nCoordinates: Latitude and longitude of study site\nDate and time: Determine solar zenith and azimuth angles\n\nCan be calculated using solar position algorithms (available in Python/R libraries or online tools)\n\nSensor geometry: View zenith and azimuth angles for BRF simulation\n\nSpectral and Spatial Configuration:\n\nSpectral bands: Match your actual sensor (e.g., hyperspectral: 400-2500 nm, Δλ = 5-10 nm)\nPixel resolution: Match image resolution (e.g., 5 cm for UAV, 10 m for Sentinel-2)\n\n\n\n7.5 3D Forest Scene Parameters\nFor forest ecosystems, additional structural detail is required (Hanousek et al. 2024):\nTwo Approaches:\n\nGeneral scene (for LUT generation):\n\nSmaller scene extent (e.g., 30m × 30m)\nMultiple structural combinations (varying LAI and canopy cover)\nCaptures full variability of the forest type\nRequires more simulations but creates comprehensive LUT\n\nExact scene (for site-specific simulation):\n\nLarger scene matching study site\nFewer combinations (only realistic structural parameters for that site)\nIncludes all factors affecting spectra at specific location\nUsed when you have detailed field data for one location\n\n\n\n\n\n\n\n\nFigure 11: 3D forest scene representation in DART. (a) Top-down view showing tree positions in systematic grid pattern with brown ground visible between crowns. (b) Oblique 3D view showing detailed tree architecture with individual crowns, trunks, and branches. Scene dimensions are 30m × 30m with trees positioned to achieve target canopy cover and LAI. Source: Hanousek et al. (2024)\n\n\n\nScene Components (Figure 11):\n\nTree positions: Define x, y coordinates for each tree\n3D tree models: Import detailed geometry (from DART database, TLS, or modeling software)\nOptical properties: Assign leaf, bark, and ground spectra to scene elements\nStructural parameters: Set LAI, canopy cover through tree density and size\n\n\n\n\n\n\n\nNoteLUT vs. Site-Specific Simulation\n\n\n\nThe DART tutorial you’ve completed shows how to create and run a single simulation with specific parameters. For trait retrieval, researchers typically create Look-Up Tables (LUTs) by running hundreds or thousands of simulations with systematically varied parameters.\nHowever, as a tutorial user, you’ll likely work with pre-generated LUTs created by research groups. Your role is understanding:\n\nHow LUTs are structured (traits → spectra relationships)\nHow to apply retrieval algorithms to your imagery\nHow scene parameters affect simulated spectra\n\nCreating large LUTs requires computational resources and expertise typically available in research labs.\n\n\n\n\n7.6 Look-Up Table Design\nLUTs form the core of RTM-based retrieval, systematically exploring the relationship between traits and spectra (Hanousek et al. 2024):\n\n\n\n\n\n\nFigure 12: Look-Up Table generation strategy. Flow diagram shows how leaf traits (chlorophyll, carotenoids, water, dry matter, structural parameter) combine with structural and scene parameters (canopy cover, LAI, sun zenith angle, sun azimuth angle). Total possible combinations: 3.5 million. Through random sampling (2000 combinations) and filtering for realism (1728 combinations remain after excluding unrealistic scenarios like low canopy cover with high LAI), these are organized into trait groups, then expanded across structural-geometric combinations, yielding a final database of 3,456,000 spectra. Source: Hanousek et al. (2024)\n\n\n\nFigure 12 shows a sophisticated LUT design for broadleaf forests. Key principles:\nParameter Space Definition:\n\nLeaf biochemistry: Chlorophyll, carotenoids, water, dry matter ranges based on literature and field data\nCanopy structure: LAI, canopy cover ranges representing forest variability\nGeometric conditions: Solar angles covering different times of day and seasons\n\nSampling Strategy:\n\nStart with all possible combinations (millions)\nApply realistic constraints (e.g., high LAI requires sufficient canopy cover)\nUse random or Latin Hypercube Sampling for efficient space coverage\nResult: Computationally feasible database (thousands to millions of spectra)\n\nPractical Considerations:\nFor the tutorial user, the key insight is that trait retrieval requires this systematic parameter exploration. Pre-generated LUTs available from research groups save you from running thousands of DART simulations yourself.\n\n\n7.7 Processing Simulated Images\nBefore using LUT spectra for retrieval, simulated images must be processed consistently with real imagery (Hanousek et al. 2024):\n\n\n\n\n\n\nFigure 13: Processing of simulated DART imagery. (a) RGB composite showing forest canopy with green sunlit leaves, dark shadows between crowns, and brown/purple mixed pixels at crown edges. (b) Binary mask isolating only sunlit leaf pixels (bright green) while excluding shadows, woody parts, and ground. This masking ensures that LUT spectra represent the same surface types as pixels used in retrieval from real imagery. Source: Hanousek et al. (2024)\n\n\n\nCritical Step: Masking (Figure 13)\nApply identical masking to simulated and observed imagery:\n\nInclude: Sunlit leaf pixels (target for trait retrieval)\nExclude:\n\nDeep shadows (too dark, unreliable spectra)\nTrunks and branches (woody parts have different optical properties)\nGround/soil (background contamination)\nMixed pixels (boundaries, reduce ambiguity)\n\n\nSpectral Processing:\n\nConvolve high-resolution RTM spectra to sensor bands\nApply atmospheric correction (if needed)\nExtract mean/median spectra from masked regions\n\nConsistency is Key:\nWhatever processing you apply to simulated images (masking, smoothing, aggregation) must be applied identically to real images. Inconsistency is a major source of retrieval errors.\n\n\n7.8 Applying Retrieval to Real Imagery\nWith a prepared LUT and processed imagery, retrieval algorithms estimate traits by matching observed spectra to the database (Slanináková et al. 2025):\n\n\n\n\n\n\nFigure 14: Comparison of retrieval methods on seasonal hyperspectral imagery. Three rows show results from Statistical (empirical regression), ALSS (Adaptive LUT Subset Selection), and LUT (full Look-Up Table matching) methods. Four columns represent different dates: 26 Apr 2019, 21 Jun 2021, 18 Jul 2019, and 22 Oct 2020. Color scale shows chlorophyll content (Cab) from 10-60 μg/cm². All methods capture seasonal variation (low chlorophyll in spring/autumn, high in summer) and spatial patterns (individual tree crowns), but differ in smoothness and detail. ALSS balances accuracy and robustness. Source: Slanináková et al. (2025)\n\n\n\nCommon Retrieval Approaches:\n\nStatistical methods: Empirical regression calibrated on field samples\n\nFast, simple, but site and sensor-specific\nShown in left column of Figure 14\n\nFull LUT matching: Find closest spectrum in entire database\n\nMost detail, but sensitive to model errors\nShown in right column of Figure 14\n\nAdaptive LUT Subset Selection (ALSS): Iteratively narrow search space\n\nBalances detail and robustness (Slanináková et al. 2025)\nShown in middle column of Figure 14\nRecommended for operational use\n\n\nKey Observations from Figure 14:\n\nAll methods capture seasonal dynamics (spring → summer → autumn)\nSpatial patterns reveal individual tree differences\nALSS provides intermediate detail level, reducing noise while preserving important variation\nChoice of method depends on priorities: speed vs. detail vs. robustness\n\nValidation:\nAlways compare retrieved traits against independent field measurements:\n\nCalculate RMSE, R², and bias\nCheck for systematic errors across trait range\nValidate on multiple dates to assess temporal consistency\n\n\n\n\n\n\n\nImportantPractical Retrieval Workflow\n\n\n\nAs a DART tutorial user, your practical retrieval workflow will likely be:\n\nObtain imagery: Acquire hyperspectral/multispectral data of your study site\nPre-process: Atmospheric correction, geometric correction, masking\nAccess LUT: Use pre-generated LUT from collaborators or published studies\nApply retrieval: Use provided algorithms (Python/R scripts) to match imagery to LUT\nValidate: Compare with field measurements\n\nYou typically won’t generate your own LUT unless working on a long-term research project with computational resources. The DART tutorial teaches you the principles behind LUT generation so you understand the retrieval process."
  },
  {
    "objectID": "topics/DART_theory.html#challenges-and-future-directions",
    "href": "topics/DART_theory.html#challenges-and-future-directions",
    "title": "Theoretical Background: Radiative Transfer Modelling for Ecosystem Monitoring",
    "section": "8 Challenges and Future Directions",
    "text": "8 Challenges and Future Directions\nWhile RTM-based retrieval is powerful, several challenges remain (Malenovský et al. 2021):\nCurrent Limitations:\n\nComputational cost: Generating large LUTs requires significant time (days to weeks)\nParameterization burden: Accurate simulations need extensive field data\nModel assumptions: Even 3D RTMs simplify reality (leaf clumping, bark texture, soil variability)\nScale mismatches: Bridging leaf-level measurements to landscape imagery\nValidation scarcity: Limited sites with comprehensive trait measurements\n\nEmerging Solutions:\n\nMachine learning emulators: Neural networks approximate RTM behavior, reducing computation by orders of magnitude (Verrelst et al. 2015)\nTLS integration: Laser scanning provides unprecedented structural detail (Janoutová et al. 2021)\nMulti-sensor fusion: Combine optical, LiDAR, and thermal for comprehensive characterization\nUncertainty quantification: Bayesian approaches provide confidence intervals, not just point estimates\nOperational pipelines: Automated systems for routine trait mapping from satellites\n\nVision for the Future:\nThe next decade will see RTM-based trait products become operational:\n\nReal-time mapping from satellite imagery\nGlobal coverage at moderate resolution (10-30 m)\nIntegration with ecosystem models for carbon cycle and climate studies\nBiodiversity monitoring through spectral diversity proxies\n\nAchieving this requires continued collaboration among remote sensing scientists, ecologists, and operational agencies."
  },
  {
    "objectID": "topics/DART_theory.html#summary-and-key-takeaways",
    "href": "topics/DART_theory.html#summary-and-key-takeaways",
    "title": "Theoretical Background: Radiative Transfer Modelling for Ecosystem Monitoring",
    "section": "9 Summary and Key Takeaways",
    "text": "9 Summary and Key Takeaways\n\nRTM FundamentalsDART ModelRetrieval WorkflowPractical AdviceFuture Outlook\n\n\n\nPhysical basis: RTMs simulate light-vegetation interactions using physics, not correlations\nScales: From leaf (micrometers) to landscape (kilometers)\nModels: 1D (homogeneous), 3D geometrical (tree shapes), 3D complex (explicit structure)\nProducts: BRF, thermal, LiDAR, radiative budget\n\n\n\n\nComprehensive: Optical, thermal, and LiDAR in one framework\nValidated: Strong performance in RAMI benchmarks\nFlexible: Multiple scene representations, 3D object import\nPractical: Tutorial teaches basic workflow for forest scenes\n\nBest for high-resolution studies requiring detailed 3D representation.\n\n\n\nField measurements: Optical properties, traits, structure\nScene setup: Configure RTM with realistic parameters\nLUT generation: Systematic parameter exploration (typically done by research labs)\nImage processing: Consistent masking and spectral processing\nRetrieval: Match observed spectra to LUT database\nValidation: Compare with independent field data\n\nCritical: Consistency between simulated and observed data processing.\n\n\n\nTutorial users: Focus on understanding principles, use pre-generated LUTs\nResearchers: Generate custom LUTs for specific ecosystems/sensors\nValidation essential: Always compare retrievals with field measurements\nMethod selection: ALSS balances accuracy and robustness\nStart simple: Master basic simulations before complex scenes\n\n\n\n\nEmulation: ML-accelerated RTMs for operational speed\nTLS integration: Explicit 3D structure from laser scanning\nMulti-sensor fusion: Optical + LiDAR + thermal\nUncertainty: Probabilistic retrievals with confidence\nGlobal products: Routine trait mapping from satellites\n\nRTMs enable quantitative ecosystem monitoring from space."
  },
  {
    "objectID": "topics/DART_theory.html#glossary-of-key-terms",
    "href": "topics/DART_theory.html#glossary-of-key-terms",
    "title": "Theoretical Background: Radiative Transfer Modelling for Ecosystem Monitoring",
    "section": "10 Glossary of Key Terms",
    "text": "10 Glossary of Key Terms\n\n\n\n\n\n\nNoteExpand Glossary\n\n\n\n\n\nAbsorption coefficient: Wavelength-specific rate at which a material absorbs photons, typically per unit path length.\nBRDF (Bidirectional Reflectance Distribution Function): Mathematical function describing how reflectance varies with all possible illumination and viewing geometries.\nBRF (Bidirectional Reflectance Factor): Ratio of reflected radiance to that from an ideal Lambertian reflector under the same illumination, for specific sun-sensor geometry.\nCanopy: Collective foliage and structure of vegetation over an area.\nDART: Discrete Anisotropic Radiative Transfer model, a comprehensive 3D RTM.\nFlux: Radiant energy passing through a surface per unit time and area (W/m²).\nHotspot: Peak in reflectance when sun and sensor are aligned (zero phase angle), due to absence of shadows.\nIrradiance: Radiant power incident on a surface per unit area (W/m²).\nLAI (Leaf Area Index): One-sided leaf area per unit ground area (m²/m²).\nLUT (Look-Up Table): Database of simulated spectra and corresponding trait values for inversion.\nMonte Carlo: Ray-tracing method using random sampling to simulate photon paths.\nPhase angle: Angle between sun, target, and sensor directions.\nPROSPECT: Plate model for simulating leaf optical properties from biochemistry.\nRadiance: Radiant power per unit solid angle per unit projected area (W/m²/sr).\nRAMI: RAdiation transfer Model Intercomparison initiative for benchmarking RTMs.\nReflectance: Ratio of reflected to incident radiant flux (dimensionless, 0-1).\nRTM (Radiative Transfer Model): Physical model simulating light propagation and interaction in vegetation.\nScattering: Redirection of photons due to interaction with particles or surfaces.\nTransmittance: Ratio of transmitted to incident radiant flux (dimensionless, 0-1).\nTurbid medium: Approximation of canopy as homogeneous layer with uniformly distributed scatterers.\nVZA (View Zenith Angle): Angle between nadir (vertical) and sensor view direction."
  },
  {
    "objectID": "topics/DART_theory.html#additional-resources",
    "href": "topics/DART_theory.html#additional-resources",
    "title": "Theoretical Background: Radiative Transfer Modelling for Ecosystem Monitoring",
    "section": "11 Additional Resources",
    "text": "11 Additional Resources\n\n\n\n\n\n\nTipLearning Materials\n\n\n\n\n\nDART Resources:\n\nDART Official Website: Downloads, manual, forum\nDART User Manual: Comprehensive guide\nDART Summer Schools: Annual training workshops\n\nKey Publications:\n\nDART model: Gastellu-Etchegorry et al. (2017)\nRetrieval methods: Dorigo et al. (2007), Verrelst et al. (2019)\nLUT design: Hanousek et al. (2024)\nALSS method: Slanináková et al. (2025)\nTLS integration: Janoutová et al. (2021)\n\nSoftware and Tools:\n\nDART: https://dart.omp.eu/\nPROSPECT: Integrated in DART\nRetrieval algorithms: Often provided as Python/R scripts by research groups"
  },
  {
    "objectID": "topics/DART_theory.html#references",
    "href": "topics/DART_theory.html#references",
    "title": "Theoretical Background: Radiative Transfer Modelling for Ecosystem Monitoring",
    "section": "12 References",
    "text": "12 References\n\n\nBailey, Brian N. 2019. “Helios: A Scalable 3D Plant and Environmental Biophysical Modeling Framework.” Frontiers in Plant Science 10: 1185. https://doi.org/10.3389/fpls.2019.01185.\n\n\nBailey, Brian N., Miguel A. Ponce de León, and E. Scott Krayenhoff. 2020. “One-Dimensional Models of Radiation Transfer in Heterogeneous Canopies: A Review, Re-Evaluation, and Improved Model.” Geoscientific Model Development 13 (10): 4789–4808. https://doi.org/10.5194/gmd-13-4789-2020.\n\n\nDorigo, W. A., R. Zurita-Milla, A. J. W. de Wit, J. Brazile, R. Singh, and M. E. Schaepman. 2007. “A Review on Reflective Remote Sensing and Data Assimilation Techniques for Enhanced Agroecosystem Modeling.” International Journal of Applied Earth Observation and Geoinformation 9 (2): 165–93. https://doi.org/10.1016/j.jag.2006.05.003.\n\n\nFéret, Jean-Baptiste, Anatoly A. Gitelson, Shawn D. Noble, and Stéphane Jacquemoud. 2017. “PROSPECT-D: Towards Modeling Leaf Optical Properties Through a Complete Lifecycle.” Remote Sensing of Environment 193: 204–15. https://doi.org/10.1016/j.rse.2017.03.004.\n\n\nGastellu-Etchegorry, Jean-Philippe, Nicolas Lauret, Tiangang Yin, Lucas Landier, Abdelaziz Kallel, Zbyněk Malenovský, Ahmad Al Bitar, et al. 2017. “DART: Recent Advances in Remote Sensing Data Modeling With Atmosphere, Polarization, and Chlorophyll Fluorescence.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 10 (6): 2640–49. https://doi.org/10.1109/JSTARS.2017.2685528.\n\n\nGastellu-Etchegorry, Jean-Philippe, Tiangang Yin, Nicolas Lauret, Thomas Cajgfinger, Thierry Gregoire, Enrique Grau, Jean-Baptiste Feret, et al. 2015. “Modeling Radiative Transfer in Heterogeneous 3-D Vegetation Canopies.” Remote Sensing of Environment 158: 131–56. https://doi.org/10.1016/j.rse.2014.10.030.\n\n\nHanousek, Tomáš, Tereza Slanináková, Tomáš Rebok, and Růžena Janoutová. 2024. “High Spatial and Spectral Resolution Dataset of Hyperspectral Look-up Tables for 3.5 Million Traits and Structural Combinations of Central European Temperate Broadleaf Forests.” Data in Brief 57: 111105. https://doi.org/10.1016/j.dib.2024.111105.\n\n\nHanuš, Jan, Lukáš Slezák, Tomáš Fabiánek, Lukáš Fajmon, Tomáš Hanousek, Růžena Janoutová, Daniel Kopkáně, et al. 2023. “Flying Laboratory of Imaging Systems: Fusion of Airborne Hyperspectral and Laser Scanning for Ecosystem Research.” Remote Sensing 15 (12): 3130. https://doi.org/10.3390/rs15123130.\n\n\nJacquemoud, Stéphane, and Frédéric Baret. 1990. “PROSPECT: A Model of Leaf Optical Properties Spectra.” Remote Sensing of Environment 34 (2): 75–91. https://doi.org/10.1016/0034-4257(90)90100-Z.\n\n\nJanoutová, Růžena, Lucie Homolová, Jan Novotný, Barbora Navrátilová, Miloš Pikl, and Zbyněk Malenovský. 2021. “Detailed Reconstruction of Trees from Terrestrial Laser Scans for Remote Sensing and Radiative Transfer Modelling Applications.” In Silico Plants 3 (2): diab026. https://doi.org/10.1093/insilicoplants/diab026.\n\n\nKnyazikhin, Yuri, John V. Martonchik, Ranga B. Myneni, David J. Diner, and Steven W. Running. 1998. “Synergistic Algorithm for Estimating Vegetation Canopy Leaf Area Index and Fraction of Absorbed Photosynthetically Active Radiation from MODIS and MISR Data.” Journal of Geophysical Research: Atmospheres 103 (D24): 32257–75. https://doi.org/10.1029/98JD02462.\n\n\nLi, Xihan, Zhuosen Sun, Shunlin Lu, and Kenji Omasa. 2025. “A Radiative Transfer Model for Characterizing Photometric and Polarimetric Properties of Leaf Reflection: Combination of PROSPECT and a Polarized Reflection Function.” Remote Sensing of Environment 318: 114559. https://doi.org/10.1016/j.rse.2024.114559.\n\n\nMalenovský, Zbyněk, Lucie Homolová, Raul Zurita-Milla, Petr Lukeš, Veronika Kaplan, Jan Hanuš, Jean-Philippe Gastellu-Etchegorry, and Michael E. Schaepman. 2013. “Retrieval of Spruce Leaf Chlorophyll Content from Airborne Image Data Using Continuum Removal and Radiative Transfer.” Remote Sensing of Environment 131: 85–102. https://doi.org/10.1016/j.rse.2012.12.015.\n\n\nMalenovský, Zbyněk, Petr Lukeš, Lucie Homolová, Henning Buddenbaum, Jochem Verrelst, Luis Alonso, Michael E. Schaepman, Nicolas Lauret, and Jean-Philippe Gastellu-Etchegorry. 2021. “Scientific and Technical Challenges in Remote Sensing of Plant Canopy Reflectance and Fluorescence.” Journal of Experimental Botany 72 (13): 6820–33. https://doi.org/10.1093/jxb/eraa575.\n\n\nMalenovskỳ, Zbyněk, Kumud Bandhu Mishra, František Zemek, Uwe Rascher, and Ladislav Nedbal. 2009. “Scientific and Technical Challenges in Remote Sensing of Plant Canopy Reflectance and Fluorescence.” Journal of Experimental Botany 60 (11): 2987–3004.\n\n\nNorth, Peter R. J. 1996. “Three-Dimensional Forest Light Interaction Model Using a Monte Carlo Method.” IEEE Transactions on Geoscience and Remote Sensing 34 (4): 946–56. https://doi.org/10.1109/36.508411.\n\n\nQi, Jianbo, Donghui Xie, Tiangang Yin, Guangjian Yan, Jean-Philippe Gastellu-Etchegorry, Liangyun Li, Wuming Zhang, Xihan Mu, and Leslie K. Norford. 2019. “LESS: LargE-Scale Remote Sensing Data and Image Simulation Framework over Heterogeneous 3D Scenes.” Remote Sensing of Environment 221: 695–706. https://doi.org/10.1016/j.rse.2018.11.036.\n\n\nSchaepman, Michael E., Susan L. Ustin, Antonio J. Plaza, Thomas H. Painter, Jochem Verrelst, and Shunlin Liang. 2009. “Earth System Science Related Imaging Spectroscopy—An Assessment.” Remote Sensing of Environment 113: S123–37. https://doi.org/10.1016/j.rse.2009.03.001.\n\n\nSlanináková, Tereza, Marian Švik, Tomáš Rebok, Tomáš Hanousek, and Růžena Janoutová. 2025. “Introducing a New Adaptive Look-up Table Subset Selection Method for Leaf Chlorophyll and Carotenoids Retrieval in Broadleaved Forests.” Remote Sensing Letters 16 (6): 676–86. https://doi.org/10.1080/2150704X.2025.2495992.\n\n\nVerhoef, Wout. 1984. “Light Scattering by Leaf Layers with Application to Canopy Reflectance Modeling: The SAIL Model.” Remote Sensing of Environment 16 (2): 125–41. https://doi.org/10.1016/0034-4257(84)90057-9.\n\n\nVerrelst, Jochem, Gustau Camps-Valls, Jordi Muñoz-Marí, Juan Pablo Rivera, Frank Veroustraete, Jan G. P. W. Clevers, and José Moreno. 2015. “Machine Learning Regression Algorithms for Biophysical Parameter Retrieval: Opportunities for Sentinel-2 and -3.” Remote Sensing of Environment 118: 273–84. https://doi.org/10.1016/j.rse.2011.11.002.\n\n\nVerrelst, Jochem, Zbyněk Malenovský, Christiaan Van der Tol, Gustau Camps-Valls, Jean-Philippe Gastellu-Etchegorry, Philip Lewis, Peter North, and José Moreno. 2019. “Quantifying Vegetation Biophysical Variables from Imaging Spectroscopy Data: A Review on Retrieval Methods.” Surveys in Geophysics 40 (3): 589–629. https://doi.org/10.1007/s10712-018-9478-y.\n\n\nWidlowski, Jean-Luc, Claudia Mio, Mathias Disney, Jennifer Adams, Ioannis Andredakis, Clement Atzberger, John Brennan, et al. 2015. “The Fourth Radiation Transfer Model Intercomparison (RAMI-IV): Proficiency Testing of Canopy Reflectance Models with ISO-13528.” Journal of Geophysical Research: Atmospheres 120 (12): 6869–90. https://doi.org/10.1002/2015JD023808.\n\n\nXu, Kai, and Hui Ye. 2023. “Light Scattering in Stacked Mesophyll Cells Results in Similarity Characteristic of Solar Spectral Reflectance and Transmittance of Natural Leaves.” Scientific Reports 13 (1): 4694. https://doi.org/10.1038/s41598-023-31718-1.\n\n\n\nThis theoretical background document is designed to accompany practical tutorials on RTM application. For hands-on guidance on using DART for forest scenes, see the companion “DART Forest Scene Setup Tutorial”."
  },
  {
    "objectID": "notebooks/intro_python.html",
    "href": "notebooks/intro_python.html",
    "title": "Sine function",
    "section": "",
    "text": "Run the following code to see the sine function.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\nplt.plot(x, y)\nplt.title('Sine Wave')\nplt.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome to Remote Sensing Lessons\nThis site provides interactive tutorials in Python and R using real-world remote sensing data.\nChoose a lesson from the navigation bar to get started."
  },
  {
    "objectID": "notebooks/r_analysis.html",
    "href": "notebooks/r_analysis.html",
    "title": "Simple Data Analysis in R",
    "section": "",
    "text": "This notebook demonstrates a basic data analysis in R using randomly generated data. We’ll compute the summary and plot a histogram.\n\n# Generate 100 random numbers from normal distribution\nx &lt;- rnorm(100)\nsummary(x)\n\n\n# Plot histogram\nhist(x, main = \"Histogram of x\", col = \"skyblue\", border = \"white\")"
  },
  {
    "objectID": "topics/DART_tutorial.html",
    "href": "topics/DART_tutorial.html",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "",
    "text": "This tutorial provides a step-by-step guide for setting up a forest scene simulation in DART (Discrete Anisotropic Radiative Transfer). DART is a comprehensive 3D radiative transfer model designed for simulating radiative budget and remote sensing acquisitions of natural and urban landscapes. This tutorial focuses on creating a high-resolution forest scene with detailed 3D tree models and proper optical properties."
  },
  {
    "objectID": "topics/DART_tutorial.html#overview",
    "href": "topics/DART_tutorial.html#overview",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "",
    "text": "This tutorial provides a step-by-step guide for setting up a forest scene simulation in DART (Discrete Anisotropic Radiative Transfer). DART is a comprehensive 3D radiative transfer model designed for simulating radiative budget and remote sensing acquisitions of natural and urban landscapes. This tutorial focuses on creating a high-resolution forest scene with detailed 3D tree models and proper optical properties."
  },
  {
    "objectID": "topics/DART_tutorial.html#prerequisites",
    "href": "topics/DART_tutorial.html#prerequisites",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\nBefore starting this tutorial, ensure you have:\n\nDART software installed (Version 5.10.5 or later)\nThe DART_forest_scene.zip file containing all necessary input files\nBasic understanding of radiative transfer modeling\nSufficient computational resources (12-core processor recommended)\n\n\n\n\n\n\n\nNoteAbout DART\n\n\n\nDART is developed by the CESBIO laboratory (Centre d’Etudes Spatiales de la BIOsphère) and provides both forward and inverse modeling capabilities for optical remote sensing. For more information, visit the DART manual."
  },
  {
    "objectID": "topics/DART_tutorial.html#part-1-initial-setup",
    "href": "topics/DART_tutorial.html#part-1-initial-setup",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "3 Part 1: Initial Setup",
    "text": "3 Part 1: Initial Setup\n\n3.1 Extracting and Organizing Files\nThe first step is to properly organize the DART project files:\n\n\n\n\n\n\nImportantFile Organization\n\n\n\nExtract the DART_forest_scene.zip file and copy all contents except the DART_directory/user_data/simulations/forest_scene/input folder to your DART installation directory. The structure should look like:\n\nDART/database ← Copy database files here\nDART/user_data ← Copy other files here (except input folder)\n\nThis ensures all necessary optical properties, 3D models, and configuration files are in the correct locations.\n\n\n\n\n3.2 Creating a New Simulation\nTo begin your forest scene simulation:\n\nOpen DART\nClick on Simulation → New Simulation\nEnter your simulation name (e.g., “forest_scene”)\nClick “New”\n\n\n\n\n\n\n\nFigure 1: DART main menu showing the Simulation options and New Simulation dialog\n\n\n\nAs shown in Figure 1, the dialog allows you to specify the simulation name and location within your simulations folder.\n\n\n\n\n\n\nTipSimulation Management Tips\n\n\n\n\nKeep all simulations in the default simulations folder for easier management\nYou can create folder structures within the simulations directory\nUse “Choose Simulations…” if you have an existing simulation to import\nUse descriptive names for your simulations for easy identification\n\n\n\n\n\n3.3 Opening the Editor\nAfter creating your simulation:\n\nClick on Parameters → Editor\nThe DART Simulation Editor window will open\nYou’re now ready to configure your simulation parameters\n\n\n\n\n\n\n\nFigure 2: Opening the DART Editor from Parameters menu\n\n\n\nThe Editor interface (Figure 2) provides access to all simulation parameters through an organized tree structure on the left side of the window."
  },
  {
    "objectID": "topics/DART_tutorial.html#part-2-core-simulation-parameters",
    "href": "topics/DART_tutorial.html#part-2-core-simulation-parameters",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "4 Part 2: Core Simulation Parameters",
    "text": "4 Part 2: Core Simulation Parameters\n\n4.1 Basic Configuration\nThe first configuration screen allows you to set fundamental simulation parameters:\n\n\n\n\n\n\nFigure 3: DART Editor showing basic configuration parameters including atmosphere settings, advanced mode, and thread configuration\n\n\n\n\n\n\n\n\n\nImportantCritical Settings\n\n\n\nAtmosphere Simulation: - Enable atmosphere simulation even if you only need “bottom of atmosphere” products - This ensures more accurate radiative transfer calculations\nThreading Configuration: - Switch to Advanced Mode - Set Number of threads in DART tracking to 12 - This optimizes performance on multi-core systems\nRadiative Transfer Mode: - For high spatial resolution forest scenes, use bi-directional Light propagation mode (DART Lux) - This provides the most accurate and computationally efficient results for detailed 3D scenes\nThese settings are highlighted in Figure 3.\n\n\n\n\n\n\n\n\nNotePython Integration\n\n\n\nThe DART team provides Python scripts that can be implemented directly in DART or used for data preparation. These scripts offer additional automation capabilities. Refer to the DART manual for more details on Python integration.\n\n\n\n\n4.2 Spectral Band Configuration\nConfigure the spectral bands for your simulation:\n\nRight-click on “Spectral intervals”\nSelect Add… → Spectral band\nAdd four spectral bands with the following specifications:\n\n\n\n\nBand Number\nMode\nCentral Wavelength (μm)\nBandwidth (μm)\n\n\n\n\n0\nMode R\n0.56\n0.032\n\n\n1\nMode R\n0.65\n0.032\n\n\n2\nMode R\n0.73\n0.032\n\n\n3\nMode R\n0.85\n0.052\n\n\n\n\n\n\n\n\n\nFigure 4: Configuration dialogs for four spectral bands showing Mode, Central wavelength, and Spectral bandwidth parameters\n\n\n\nFigure 4 shows the configuration windows for all four spectral bands. Each band is set to Mode R (reflectance) with specific central wavelengths and bandwidths appropriate for vegetation monitoring.\n\n\n\n\n\n\nTipWorking with Multiple Bands\n\n\n\n\nFor larger numbers of spectral bands, use “Add range of…” method\nIf bands have varying bandwidths, directly modify the $your_simulation_name/input/phase.xml file\nThis approach is more efficient for hyperspectral simulations"
  },
  {
    "objectID": "topics/DART_tutorial.html#part-3-scene-configuration",
    "href": "topics/DART_tutorial.html#part-3-scene-configuration",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "5 Part 3: Scene Configuration",
    "text": "5 Part 3: Scene Configuration\n\n5.1 Bi-directional Parameters\nConfigure the image rendering and computation parameters:\n\n\n\n\n\n\nFigure 5: Bi-directional parameters panel showing pixel size, rendering settings, and radiative budget options\n\n\n\n\n\n\n\n\n\nImportantKey Parameters\n\n\n\nImage Resolution: - Set Target pixel size [m] to 0.05 (5 cm) - This provides high-resolution output suitable for detailed analysis\nOptimized Parameters: These values are results of optimization and consultation with the DART team: - Target sample density per pixel (images): 50 - Maximal rendering time per image: 2000 - Number of repetitions of the user-defined scene: 1\nRadiation Settings: - Sampler: Sobol - Russian Roulette Acceleration: Enable (checked)\nPeriodic Save: - Periodic save method: No periodic save\nAll these parameters are shown in Figure 5 with their recommended values highlighted.\n\n\n\n\n\n\n\n\nNoteParameter Optimization\n\n\n\nWhen starting a new simulation type, it’s recommended to verify these parameters for your specific: - Scene type (forest, urban, agricultural) - Spatial resolution requirements - Spectral resolution needs\nParameter optimization can significantly affect both accuracy and computation time.\n\n\n\n\n5.2 Output Products Configuration\nConfigure which products DART will generate:\n\nNavigate to Products → BRF/BTF\nEnable “Write BRF/BTF files and maps”\nSet Type of color/model of Earth scene element: Reflectance/Temperature\nConfigure Images - stored per band (folder):\n\nFormat: Ilwis (.mpr) and netcdf (.nc)\nMaximum VZA for storing images: 1.0\n\nDisable Sensor plane images\n\n\n\n\n\n\n\nFigure 6: Products configuration panel showing BRF/BTF settings and image format options\n\n\n\nAs shown in Figure 6, only the necessary outputs are enabled to minimize computation time and storage requirements.\n\n\n\n\n\n\nTipOutput Format\n\n\n\n\nDART is transitioning to netcdf as the primary output format\nIlwis format is included here for compatibility with this tutorial\nAdditional products can be enabled but will increase computation time and storage requirements\nOnly enable the products you actually need for your analysis"
  },
  {
    "objectID": "topics/DART_tutorial.html#part-4-optical-properties",
    "href": "topics/DART_tutorial.html#part-4-optical-properties",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "6 Part 4: Optical Properties",
    "text": "6 Part 4: Optical Properties\n\n6.1 Leaf Optical Properties\nDefine the spectral properties of leaves using the PROSPECT model:\n\nRight-click on “Lambertian” section\nSelect Add → Lambertian (or modify the default)\nConfigure the following:\n\nBasic Settings: - Lambertian property name: “leaves” - Disable “Multiplicative factor for database” - Enable “Reflectance, transmittance” in the Prospect section\nPROSPECT Parameters: Use the PROSPECT leaf radiative transfer model with these default biochemical parameters: - Structure coefficient: 1.5 - Chlorophyll: 40 - Carotenoid: 10 - Brown pigment: 0.0 - Equivalent water thickness: 0.012 - Anthocyanin: 0 - Dry matter content: Dry matter content\n\n\n\n\n\n\nFigure 7: Lambertian optical properties configuration for leaves using PROSPECT model with biochemical parameters\n\n\n\nFigure 7 demonstrates the complete PROSPECT configuration for leaf optical properties, including all biochemical parameters that drive the spectral response.\n\n\n\n\n\n\nNotePROSPECT Model\n\n\n\nThe PROSPECT model is a leaf-level radiative transfer model that simulates leaf optical properties based on biochemical composition. These parameters will be used for: - Look-Up Table (LUT) generation - Parameter retrieval from remote sensing images - Sensitivity analysis\nThe multiplicative factor option allows scaling of optical properties by a constant value when needed.\n\n\n\n\n6.2 Bark Optical Properties\nDefine spectral properties for tree bark:\n\nRight-click on “Lambertian”\nSelect Add → Lambertian\nConfigure:\n\nDatabase Selection: - Lambertian property name: “bark” - Disable “Multiplicative factor for database” - 2D lambertian database: Select lanzhot_materials.db - 2D lambertian model: Select trunk_FA_SY_QE_sp_Lanzhot_fix\n\n\n\n\n\n\nFigure 8: Lambertian optical properties configuration for bark using measured spectral data from lanzhot_materials database\n\n\n\nThe bark optical properties (Figure 8) use measured spectral reflectance data from the Lanzhot forest site, providing realistic bark reflectance characteristics.\n\n\n\n\n\n\nTipOptical Property Databases\n\n\n\n\nThe lanzhot_materials.db file should be in your DART/database folder (from the extracted zip)\nYou can also use optical properties from DART’s default Lambertian_vegetation.db\nUse DART Database Manager (Tools menu) to create or modify optical property databases\nMeasured optical properties provide more realistic simulations than generic values\n\n\n\n\n\n6.3 Ground Optical Properties\nDefine the forest floor spectral properties:\n\nRight-click on the bark optical properties\nSelect Duplicate\nModify:\n\nLambertian property name: “ground”\n2D lambertian model: Select forestfloor_LZ_mod_fix_txt\n\n\n\n\n\n\n\n\nFigure 9: Lambertian optical properties configuration for ground/forest floor using forestfloor spectral data\n\n\n\nThis creates optical properties representing the forest understory and leaf litter, as shown in Figure 9."
  },
  {
    "objectID": "topics/DART_tutorial.html#part-5-earth-scene-configuration",
    "href": "topics/DART_tutorial.html#part-5-earth-scene-configuration",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "7 Part 5: Earth Scene Configuration",
    "text": "7 Part 5: Earth Scene Configuration\n\n7.1 Scene Dimensions and Location\nSet up the basic scene parameters:\nScene Dimensions: - X max: 30 m - Y max: 30 m\nGround Properties: - Optical property name: “ground”\nGeographic Location: Set coordinates for central Czech Republic: - Altitude of the DEM zero level: 500 m - Latitude: [50°; 30’] - Longitude: [17°; 50’]\n\n\n\n\n\n\nFigure 10: Earth Scene configuration panel showing scene dimensions, ground optical properties, and geographic location\n\n\n\nFigure 10 displays the complete Earth Scene configuration, including the scene extent, ground properties, and geographic coordinates that define the simulation environment.\n\n\n\n\n\n\nNoteScene Configuration Options\n\n\n\nExactly Periodic Scene: - Isolated scene: Light crossing edges disappears (boundary effects) - Repetitive scene: Scene is virtually replicated around the edges (reduces boundary effects) - Infinite slope: Appropriate for sloped terrain\nCell Dimensions: - These parameters are irrelevant for bi-directional mode - In other modes, they correspond to simulated image spatial resolution"
  },
  {
    "objectID": "topics/DART_tutorial.html#part-6-3d-scene-objects",
    "href": "topics/DART_tutorial.html#part-6-3d-scene-objects",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "8 Part 6: 3D Scene Objects",
    "text": "8 Part 6: 3D Scene Objects\n\n8.1 Importing Tree Field Data\nAdd the tree locations and specifications:\n\nRight-click on “Object fields”\nSelect Add → Field\nField description file: Select beech.txt (from the extracted zip)\nName: “Field”\nEnable “Show this field’s objects in the 2D view”\n\n\n\n\n\n\n\nFigure 11: Field import dialog showing the beech.txt file selection and configuration options\n\n\n\nFigure 11 shows the field import interface where you specify the text file containing tree positions and properties.\n\n\n\n\n\n\nNoteField File Format\n\n\n\nThe beech.txt file contains information for each tree: - Species/object type identifier - XY position coordinates - Scaling factor (tree size) - Rotation angles\nThis format allows efficient specification of multiple objects without manually placing each one. Refer to the DART manual for detailed file format specifications.\n\n\n\n\n8.2 Importing 3D Tree Models\nImport the first tree model:\n\nRight-click on “3D Models”\nSelect Import file\nChoose the first 3D object file: beech_20 (from extracted files)\n\nConfiguration: - Name: “beech_20” - Color: Select a distinctive color (e.g., orange) - Keep other options at default\n\n\n\n\n\n\nFigure 12: 3D model import interface showing file selection, naming options, and display settings for the beech_20 tree model\n\n\n\nThe 3D model import dialog (Figure 12) allows you to specify the model file, assign a name, and configure display properties including color coding for easy identification in the 2D view.\n\n\n\n\n\n\nTip3D Object Creation\n\n\n\nDART includes a “Creation of 3D objects” tool for generating simple geometric crown shapes filled with leaf facets. While less detailed than full 3D scanned models, this can be sufficient for many applications and is computationally efficient.\n\n\n\n\n8.3 Configuring Leaf Groups\nFor the leaves group within the 3D object:\n\nExpand the tree model in the hierarchy\nSelect the leaves group\nConfigure:\n\nGroup Settings: - Name: “leaves” - Enable “Double face” ✓\nOptical Properties: - Type of optical property: Lambertian - Optical property name: “leaves”\nDisplay: - Group’s color: Leaf (green)\n\n\n\n\n\n\nFigure 13: Leaves group configuration showing double face option, optical property assignment, and the 2D view with colored tree crowns\n\n\n\nFigure 13 demonstrates the leaves group configuration within the 3D object hierarchy, with the 2D view showing the spatial distribution of trees in the scene.\n\n\n\n\n\n\nImportantDouble Face Option\n\n\n\nThe “Double face” option is critical for leaves. It ensures: - Both sides of leaf facets have optical properties - Proper simulation of leaf transmittance - Accurate light scattering within the canopy\nWithout this option, the back face of leaves would be transparent, leading to incorrect radiative transfer calculations.\n\n\n\n\n\n\n\n\nNoteTurbid Medium Alternative\n\n\n\nThe “Used to create turbid or fluid volume” option converts 3D objects into a turbid medium representation. This is useful for: - Easily changing LAI values without multiple 3D models - Computational efficiency in some cases\nHowever, it reduces spatial accuracy and makes bi-directional mode less efficient. Use only when appropriate for your application.\n\n\n\n\n8.4 Configuring Woody Parts\nFor the trunk and branches group:\n\nSelect the wooden parts group\nConfigure:\n\nGroup Settings: - Name: “wooden_parts” - Enable “Double face” ✓ (recommended)\nOptical Properties: - Type of optical property: Lambertian - Optical property name: “bark”\nDisplay: - Group’s color: Trunk (brown)\n\n\n\n\n\n\nFigure 14: Woody parts group configuration showing optical property assignment to bark and the 2D scene view\n\n\n\nThe woody parts configuration (Figure 14) assigns bark optical properties to trunk and branch components of the tree model.\n\n\n\n\n\n\nTipDouble Face for Woody Parts\n\n\n\nFor trunks and branches with no transmittance, double face is technically unnecessary if all facet normals are correctly oriented. However, enabling it is safer unless you’re certain about facet orientation, as it prevents rendering artifacts.\n\n\n\n\n8.5 Adding All Tree Models\nRepeat the import and configuration process for all remaining 3D tree models:\n\nbeech_27\nbeech_28\nbeech_62\n\nFor each model: 1. Import the 3D file 2. Set a unique name 3. Assign a distinctive color for visualization 4. Configure leaf groups with “leaves” optical properties 5. Configure woody groups with “bark” optical properties 6. Enable double face for both groups\n\n\n\n\n\n\nFigure 15: Complete 2D view of the forest scene showing all imported tree models as colored circles representing different tree types and sizes\n\n\n\n\n\n\n\n\n\nNoteVisualization\n\n\n\nWhen all models are imported and configured, the 2D editor view (Figure 15) displays colored circles representing tree crowns at their specified locations. Different colors help distinguish between different tree models or size classes. The spatial distribution shown here matches the specifications in the beech.txt field file."
  },
  {
    "objectID": "topics/DART_tutorial.html#part-7-atmospheric-configuration-optional",
    "href": "topics/DART_tutorial.html#part-7-atmospheric-configuration-optional",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "9 Part 7: Atmospheric Configuration (Optional)",
    "text": "9 Part 7: Atmospheric Configuration (Optional)\nThe atmosphere section provides detailed control over atmospheric radiative transfer:\n\n\n\n\n\n\nFigure 16: Atmosphere configuration panel showing atmospheric database selection, gas profiles, aerosol properties, and advanced mode settings"
  },
  {
    "objectID": "topics/DART_tutorial.html#atmospheric-parameters",
    "href": "topics/DART_tutorial.html#atmospheric-parameters",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "10 Atmospheric Parameters",
    "text": "10 Atmospheric Parameters\nIf you have measured or observed atmospheric data, you can configure:\nAtmosphere Database: - Select appropriate atmospheric model (e.g., BIRND_JULY2020.db)\nGas Composition: - Temperature profile (US standard models available) - Ozone and other gas vertical profiles - CO2 mixing ratio - Water vapor content\nAerosol Properties: - Set gas amounts (H2O, CO2) - Configure aerosol optical depth - Define atmospheric components (Downward fluxes, Upward fluxes)\nAdvanced Settings: - Atmosphere extrapolation parameters - Scattering threshold - Maximum scattering iteration number - Atmosphere geometry (discretization, sensor layer altitude)\nThese parameters (Figure 16) significantly affect top-of-atmosphere and atmospheric correction simulations."
  },
  {
    "objectID": "topics/DART_tutorial.html#part-8-running-the-simulation",
    "href": "topics/DART_tutorial.html#part-8-running-the-simulation",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "11 Part 8: Running the Simulation",
    "text": "11 Part 8: Running the Simulation\n\n11.1 Saving and Validation\nBefore running:\n\nClick the Save button in the Editor\nVerify no error messages appear\nReview the 2D scene view to confirm proper placement\nClose the Editor\n\n\n\n11.2 Running DART Modules\nExecute the simulation:\n\nIn the main DART window, click Run → DART\nThis runs all four modules in sequence:\n\nDirection: Calculates sun and viewing geometry\nPhase: Processes spectral and optical properties\nMaket: Constructs the 3D scene\nDart: Performs radiative transfer calculations\n\n\n\n\n\n\n\n\nFigure 17: DART Run menu showing all available modules including Direction, Phase, Maket, Dart, and auxiliary tools\n\n\n\nFigure 17 displays the Run menu with all DART modules. The execution order is important, as each module depends on the outputs of previous modules.\n\n\n\n\n\n\nImportantModule Dependencies\n\n\n\nFirst Run: - All modules must be executed\nSubsequent Runs: - Only run modules affected by parameter changes - Module dependencies: - Direction: Affects sun/sensor geometry - Phase: Affects spectral bands and optical properties - Maket: Affects scene structure and objects - Dart: Affected by all previous modules\nThis selective execution saves considerable computation time during parameter optimization.\n\n\n\n\n\n\n\n\nTipComputation Time\n\n\n\nExpected computation times vary based on: - Number of spectral bands (currently 4) - Scene complexity (30m × 30m with multiple trees) - Spatial resolution (5 cm pixels) - Number of threads (12 recommended)\nFor this configuration, expect 30-60 minutes on a modern 12-core system."
  },
  {
    "objectID": "topics/DART_tutorial.html#part-9-sequence-launcher-for-lut-generation",
    "href": "topics/DART_tutorial.html#part-9-sequence-launcher-for-lut-generation",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "12 Part 9: Sequence Launcher for LUT Generation",
    "text": "12 Part 9: Sequence Launcher for LUT Generation\nThe Sequence Launcher is a powerful tool for generating Look-Up Tables (LUTs) by systematically varying parameters:\n\n12.1 Setting Up a Sequence\n\nClick Run → SequenceLauncher\nClick “Create sequence”\nClick “Add”\nSelect parameters to vary:\n\nNavigate through the parameter tree\nSelect optical properties or structural parameters\nDefine the range of values\n\n\n\n\n\n\n\n\nFigure 18: Sequence Launcher interface showing (left) execution progress, (center) parameter selection tree, and (right) process configuration options\n\n\n\nFigure 18 shows the complete Sequence Launcher workflow, including the parameter selection dialog, the properties group details window, and the main processes configuration panel where you can specify which DART modules to run and how many simulations to execute in parallel.\n\n\n12.2 Configuration Options\nParameter Selection: Choose which parameters to vary, such as: - PROSPECT biochemical parameters (Chlorophyll, LAI, etc.) - Structural parameters (tree dimensions, densities) - Atmospheric conditions - Sun angles\nProcess Configuration: In Preferences → Process and threads to run: - Select which modules to run (based on changed parameters) - Set number of parallel simulations - Each simulation uses the specified number of threads\n\n\n\n\n\n\nTipParallel Processing\n\n\n\nExample configuration for 12-core system: - Threads per simulation: 3 - Parallel simulations: 4 - Total thread usage: 12\nBalance parallel simulations and threads per simulation based on your system’s capabilities and memory.\n\n\n\n\n12.3 Running the Sequence\n\nClick “Prepare and run sequence”\nMonitor progress in the console window\nResults will be saved in numbered subdirectories\n\n\n\n\n\n\n\nNoteLUT Applications\n\n\n\nGenerated LUTs are valuable for: - Parameter retrieval from remote sensing data - Sensitivity analysis - Model inversion - Uncertainty quantification - Training machine learning models\nThe systematic parameter variation creates a database relating scene parameters to simulated reflectance."
  },
  {
    "objectID": "topics/DART_tutorial.html#summary-and-best-practices",
    "href": "topics/DART_tutorial.html#summary-and-best-practices",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "13 Summary and Best Practices",
    "text": "13 Summary and Best Practices\n\nScene SetupOptical PropertiesComputational EfficiencyQuality Control\n\n\nEssential Steps: - Proper file organization in DART directories - Careful spectral band configuration - Appropriate spatial resolution for application - Realistic optical properties from measurements\nCommon Mistakes to Avoid: - Forgetting to enable double face for leaves - Incorrect spectral bandwidth settings - Insufficient spatial resolution - Isolated scene boundaries causing edge effects\n\n\nBest Practices: - Use measured optical properties when available - Validate PROSPECT parameters against lab measurements - Consider seasonal variations in leaf properties - Document all optical property sources\nConsiderations: - Bark properties vary by species and condition - Understory optical properties affect overall scene reflectance - Leaf age and health influence biochemical parameters\n\n\nOptimization Strategies: - Use appropriate thread count for your system - Enable Russian Roulette acceleration - Optimize rendering time parameters - Only generate needed output products - Use periodic scene boundaries to reduce edge effects\nResource Requirements: - RAM: 16-32 GB recommended for large scenes - Storage: Plan for large output files (GB per simulation) - CPU: Multi-core processor essential for reasonable run times\n\n\nValidation Steps: - Visual inspection of 2D scene layout - Check for error messages in Editor - Verify spectral signatures are realistic - Compare with field measurements if available - Test with simplified scenes first\nTroubleshooting: - Save frequently during setup - Test with single spectral band initially - Use smaller scene for parameter testing - Check DART manual for error messages"
  },
  {
    "objectID": "topics/DART_tutorial.html#advanced-topics",
    "href": "topics/DART_tutorial.html#advanced-topics",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "14 Advanced Topics",
    "text": "14 Advanced Topics\n\n14.1 Custom 3D Objects\nCreating your own tree models:\n\n\n\n\n\n\nTip3D Object Requirements\n\n\n\nDART accepts 3D objects in several formats: - OBJ (most common) - PLY - FBX (with conversion)\nRequirements: - Properly defined groups (leaves, trunk, branches) - Correct facet normals - Reasonable polygon count (balance detail vs. computation) - Separate materials for different components\n\n\n\n\n14.2 Python Integration\nDART supports Python scripting for:\n\nAutomated parameter sweeps\nCustom scene generation\nPost-processing workflows\nIntegration with other tools\n\nSee the DART manual for Python API documentation.\n\n\n14.3 Atmosphere Modeling\nFor detailed atmospheric studies:\n\nUse measured atmospheric profiles when available\nConsider aerosol optical depth variations\nAccount for water vapor absorption\nValidate against AERONET data\n\n\n\n14.4 Validation Approaches\nRecommended validation methods:\n\nLab measurements: Compare PROSPECT outputs to spectroradiometer data\nField campaigns: Validate scene reflectance with handheld or UAV spectrometers\nCross-comparison: Compare with other radiative transfer models (PROSAIL, librat)\nSensitivity analysis: Use Sequence Launcher to assess parameter impacts"
  },
  {
    "objectID": "topics/DART_tutorial.html#additional-resources",
    "href": "topics/DART_tutorial.html#additional-resources",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "15 Additional Resources",
    "text": "15 Additional Resources\n\n\n\n\n\n\nNoteLearning Resources\n\n\n\nDART Documentation: - Official DART Website - User manual (included with installation) - Tutorial collection - Forum for user questions\nScientific Background: - Gastellu-Etchegorry et al. publications on DART methodology - Remote sensing textbooks on radiative transfer - PROSPECT model documentation\nCommunity: - DART user mailing list - Annual DART training workshops - CESBIO laboratory contacts\n\n\n\n\n\n\n\n\nWarningImportant Considerations\n\n\n\nModel Limitations: - DART is computationally intensive for large scenes - Accuracy depends on input data quality - Simplified atmospheric models may not capture all effects - 3D object complexity affects computation time\nData Requirements: - Accurate 3D scene geometry - Validated optical properties - Appropriate atmospheric parameters - Sufficient computational resources\nApplication Scope: DART is suitable for: ✓ Forest and vegetation studies ✓ Urban remote sensing ✓ Precision agriculture ✓ Sensor design and testing\nMay be excessive for: ✗ Simple BRDF calculations (use simpler models) ✗ Very large spatial extents (consider other approaches) ✗ Real-time applications (computation time prohibitive)"
  },
  {
    "objectID": "topics/DART_tutorial.html#conclusion",
    "href": "topics/DART_tutorial.html#conclusion",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "16 Conclusion",
    "text": "16 Conclusion\nThis tutorial has walked through the complete workflow for setting up a forest scene simulation in DART. The combination of detailed 3D objects, measured optical properties, and physically-based radiative transfer provides a powerful tool for remote sensing research and application development.\nKey takeaways:\n\nProper setup is crucial: Careful attention to file organization, optical properties, and scene configuration ensures successful simulations\nBi-directional mode is optimal: For high-resolution 3D scenes, DART Lux provides the best balance of accuracy and efficiency\nValidation is essential: Compare simulations with field measurements whenever possible\nSequence Launcher enables systematic analysis: Use this tool for parameter studies and LUT generation\nComputational resources matter: Plan for significant computation time and storage requirements\n\nThe skills developed in this tutorial provide a foundation for more advanced DART applications, including multi-temporal studies, sensor simulation, and parameter retrieval from remote sensing data.\n\nThis tutorial is based on DART version 5.10.5. While the core concepts remain consistent across versions, specific interface details may vary. Always refer to the official DART documentation for the most current information."
  },
  {
    "objectID": "topics/DART_tutorial.html#appendix-common-issues-and-solutions",
    "href": "topics/DART_tutorial.html#appendix-common-issues-and-solutions",
    "title": "DART Forest Scene Setup Tutorial",
    "section": "17 Appendix: Common Issues and Solutions",
    "text": "17 Appendix: Common Issues and Solutions\n\nInstallation IssuesSimulation ErrorsOutput IssuesScene Configuration\n\n\nProblem: DART won’t start - Check Java installation (required) - Verify environment variables - Run from command line for error messages\nProblem: Database files not found - Verify file paths in simulation settings - Check that extracted files are in correct DART directories - Use absolute paths if relative paths fail\n\n\nProblem: Out of memory errors - Reduce scene size or resolution - Decrease number of threads - Increase Java heap size in DART configuration\nProblem: Very slow execution - Verify thread count settings - Check for excessive output products - Consider using coarser resolution for testing\n\n\nProblem: Images not generated - Check “Products” configuration - Verify maximal VZA settings - Ensure sufficient disk space - Check write permissions\nProblem: Unexpected spectral values - Verify optical property assignments - Check for missing double face settings - Validate PROSPECT parameters\n\n\nProblem: Trees not visible in 2D view - Enable “Show this field’s objects in the 2D view” - Check field file format and paths - Verify tree positions are within scene bounds\nProblem: Optical properties not applied - Confirm optical property names match - Check database file paths - Verify group assignments in 3D objects"
  },
  {
    "objectID": "topics/hyperspectral_theory.html",
    "href": "topics/hyperspectral_theory.html",
    "title": "Theoretical Background: Hyperspectral Remote Sensing of Plant Functional Traits",
    "section": "",
    "text": "Remote sensing technology enables us to observe and quantify plant characteristics across scales, from individual leaves to entire ecosystems. At the heart of this capability lies the fundamental principle that different plant compounds interact uniquely with electromagnetic radiation (Gates et al. 1965). While human vision is limited to three broad spectral bands (red, green, and blue), hyperspectral sensors capture reflectance across hundreds of narrow, contiguous wavelength bands, revealing detailed information about plant biochemistry, physiology, and structure that remains invisible to the naked eye (Ustin and Gamon 2010).\nThe interaction between light and vegetation is governed by the absorption, transmission, and reflection properties of various biochemical compounds within plant tissues. Each pigment, structural component, and water molecule creates a characteristic spectral signature—a unique pattern of absorption and reflection across the electromagnetic spectrum (Jacquemoud and Baret 1990). By analyzing these signatures, we can non-destructively estimate pigment concentrations, assess physiological status, detect stress, and classify vegetation types (Peñuelas et al. 1993)."
  },
  {
    "objectID": "topics/hyperspectral_theory.html#introduction-the-spectral-language-of-vegetation",
    "href": "topics/hyperspectral_theory.html#introduction-the-spectral-language-of-vegetation",
    "title": "Theoretical Background: Hyperspectral Remote Sensing of Plant Functional Traits",
    "section": "",
    "text": "Remote sensing technology enables us to observe and quantify plant characteristics across scales, from individual leaves to entire ecosystems. At the heart of this capability lies the fundamental principle that different plant compounds interact uniquely with electromagnetic radiation (Gates et al. 1965). While human vision is limited to three broad spectral bands (red, green, and blue), hyperspectral sensors capture reflectance across hundreds of narrow, contiguous wavelength bands, revealing detailed information about plant biochemistry, physiology, and structure that remains invisible to the naked eye (Ustin and Gamon 2010).\nThe interaction between light and vegetation is governed by the absorption, transmission, and reflection properties of various biochemical compounds within plant tissues. Each pigment, structural component, and water molecule creates a characteristic spectral signature—a unique pattern of absorption and reflection across the electromagnetic spectrum (Jacquemoud and Baret 1990). By analyzing these signatures, we can non-destructively estimate pigment concentrations, assess physiological status, detect stress, and classify vegetation types (Peñuelas et al. 1993)."
  },
  {
    "objectID": "topics/hyperspectral_theory.html#seasonal-dynamics-and-plant-functional-strategies",
    "href": "topics/hyperspectral_theory.html#seasonal-dynamics-and-plant-functional-strategies",
    "title": "Theoretical Background: Hyperspectral Remote Sensing of Plant Functional Traits",
    "section": "2 Seasonal Dynamics and Plant Functional Strategies",
    "text": "2 Seasonal Dynamics and Plant Functional Strategies\nPlants exhibit remarkable temporal variability in their spectral properties, driven by phenological cycles, resource allocation strategies, and environmental responses (Richardson et al. 2018). Understanding these dynamics is fundamental to interpreting remote sensing data correctly.\nFigure 1 illustrates the dramatic differences between plant functional types and their seasonal trajectories. The comparison between flowers/fruits and leaves demonstrates distinct spectral behaviors, while the seasonal progression from winter dormancy through spring leaf flush, summer maturity, and autumn senescence shows systematic changes in reflectance patterns (Huete et al. 2002). The tree diagrams depicting seasonal leaf development—from bare branches in winter, through flowering in spring, full canopy development in summer, to leaf senescence and abscission in autumn—provide a conceptual framework for understanding temporal spectral variability.\n\n\n\n\n\n\nFigure 1: Seasonal phenological patterns in plant functional traits. a: Photographs showing inflorescence and fruits (top row) and leaf phenology (bottom row) in deciduous trees across seasons. b: Seasonal tree phenology diagrams from winter through autumn. Source: Golan-Goldhirsch A., Kozhoridze G., et al. (unpublished work).\n\n\n\nThe distinction between mature leaves, juvenile leaves, and senescence leaves highlights that not all foliage within a canopy shares identical spectral properties (Asner and Martin 2015). This heterogeneity must be considered when scaling from leaf-level measurements to canopy or landscape observations.\nMoreover, while the general phenological pattern—spring green-up, summer maturity, autumn senescence—is shared across many temperate plant species, the timing, magnitude, and spectral characteristics of these transitions vary systematically among species (Richardson et al. 2018; Asner and Martin 2015). Different species exhibit distinct phenological schedules: some leaf out earlier in spring, others maintain green foliage longer into autumn, and evergreen species show entirely different seasonal patterns. These species-specific differences in phenological timing and pigment dynamics create unique spectral-temporal signatures that enable remote differentiation and mapping of plant species or functional types across landscapes (Ustin and Gamon 2010). By tracking how reflectance changes over time, rather than relying on snapshots from single dates, researchers can leverage these phenological differences to improve vegetation classification and monitor ecosystem composition (Richardson et al. 2018)."
  },
  {
    "objectID": "topics/hyperspectral_theory.html#pigment-specific-spectral-signatures",
    "href": "topics/hyperspectral_theory.html#pigment-specific-spectral-signatures",
    "title": "Theoretical Background: Hyperspectral Remote Sensing of Plant Functional Traits",
    "section": "3 Pigment-Specific Spectral Signatures",
    "text": "3 Pigment-Specific Spectral Signatures\nPigment concentrations show typical temporal patterns throughout the growing season. Because each pigment type is characterized by specific spectral signature (Figure 2), specific concentrations of different pigments result in a specific overall spectral response of a leave. This enables us to detect phenology and health status of trees by spectral measurements. The following three key phenological stages can be determined:\n\nEarly season dynamics (March-May): Rapid increases in pigment concentrations as leaves develop, starting with anthocyanins (red juvenile leaves) and followed by chlorophyll content rising sharply during leaf expansion (Richardson et al. 2013).\nMid-season stability (June-August): Relatively stable biochemical composition during peak photosynthetic activity, though with notable variability reflecting environmental conditions and stress responses. Chloropylles are dominating (green mature leaves), unless stress conditions lead to increased dominance of other pigments (anthocyanins, carotenoids).\nLate season senescence (September-October): Declining chlorophyll with differential changes in other compounds, creating the characteristic autumn coloration (Gitelson and Merzlyak 2001).\n\n\n\n\n\n\n\nFigure 2: Spectral signatures of major plant pigments across the visible spectrum (400-800 nm). Top: Chlorophyll spectral reflectance showing characteristic absorption bands at 520-570 nm and 695-735 nm with near-infrared plateau at 750-800 nm. Middle: Carotenoid reflectance patterns with absorption features at 500-520 nm, 540-560 nm, and 700-710 nm. Bottom: Anthocyanin spectral signature showing strong absorption in the green-yellow region (540-560 nm) and at 700-710 nm. Colored boxes indicate key wavelength regions used in vegetation index formulations (Gitelson, Keydan, and Merzlyak 2006).\n\n\n\n\n3.1 Chlorophylls: The Primary Photosynthetic Pigments\nChlorophylls are the dominant pigments in healthy, photosynthetically active vegetation, and their spectral signature forms the foundation of vegetation remote sensing (Gitelson, Gritz, and Merzlyak 2003). Figure 2 shows the characteristic double absorption pattern of chlorophylls: strong absorption centered around 430 nm in the blue region and around 680 nm in the red region, corresponding to the absorption peaks of chlorophyll a and b (Lichtenthaler 1987). Between these absorption features, green light (520-570 nm) experiences relatively less absorption, explaining why healthy vegetation appears green to our eyes.\nThe key spectral regions for chlorophyll detection are:\n\nBlue absorption (430-490 nm): Primary absorption band, but less commonly used for chlorophyll estimation due to interference from carotenoids and atmospheric scattering (Gitelson and N 1996)\nGreen peak (520-570 nm): Local reflectance maximum where chlorophyll absorption is minimal\nRed absorption (660-690 nm): Deep absorption feature, highly sensitive to chlorophyll concentration\nRed edge (690-740 nm): Steep transition from red absorption to near-infrared plateau, extremely sensitive to chlorophyll content (Horler, Dockray, and Barber 1983)\nNear-infrared plateau (750-800 nm and beyond): High reflectance due to leaf internal structure, minimally affected by pigments (Gates et al. 1965)\n\nThe reciprocal reflectance model underlying vegetation indices for chlorophyll typically uses these wavelength regions (Gitelson and Merzlyak 2006):\n\\[(1/R_{695-735} - 1/R_{750-800}) \\times R_{750-800}\\]\nwhere the near-infrared term serves to normalize for structural effects and the difference in reciprocal reflectance quantifies chlorophyll absorption.\n\n\n3.2 Carotenoids: Accessory Pigments and Photoprotection\nCarotenoids serve dual roles in plant physiology: light harvesting in the photosynthetic apparatus and photoprotection against excess light energy (Demmig-Adams and Adams III 2006). Their spectral signature differs systematically from chlorophylls. Figure 2 demonstrates that carotenoids create characteristic absorption features in:\n\nBlue region (440-520 nm): Strong absorption overlapping with chlorophyll\nBlue-green transition (500-540 nm): Primary diagnostic region where carotenoid absorption distinguishes them from chlorophylls\nGreen region (540-560 nm): Moderate absorption creating the yellow-orange appearance of carotenoid-rich tissues\nRed region (650-710 nm): Minimal absorption, contrasting with strong chlorophyll absorption\n\nThe spectral separation of carotenoids from chlorophylls becomes particularly important during senescence or stress conditions when the chlorophyll:carotenoid ratio changes dramatically (Gitelson et al. 2002). Vegetation indices designed to estimate carotenoids exploit the differential absorption at 500-520 nm and 540-560 nm relative to the near-infrared reference, following a similar reciprocal reflectance formulation:\n\\[(1/R_{500-520} - 1/R_{700-710}) \\times R_{750+}\\]\n\n\n3.3 Anthocyanins: Stress Response and Senescence Indicators\nAnthocyanins represent a distinct class of pigments that accumulate in response to various stresses—environmental, pathogenic, or developmental (Gould 2004). Unlike chlorophylls and carotenoids, which reside in chloroplasts, anthocyanins accumulate in vacuoles and can mask the spectral signatures of photosynthetic pigments (Merzlyak, Gitelson, and Chivkunova 1999).\nFigure 2 shows that anthocyanins create strong absorption in:\n\nGreen-yellow region (540-600 nm): Primary absorption feature, explaining the red-purple appearance of anthocyanin-rich tissues\nOverlap with chlorophyll green peak (520-560 nm): This overlap complicates the interpretation of reflectance in this region\n\nThe reciprocal reflectance model for anthocyanins uses (Merzlyak, Gitelson, and Chivkunova 1999):\n\\[(1/R_{540-560} - 1/R_{700-710}) \\times R_{750+}\\]\nwhere the denominator wavelength is chosen to minimize chlorophyll interference while capturing anthocyanin absorption.\n\n\n\n\n\n\nFigure 3: Seasonal variation in anthocyanin content and spectral reflectance. Spectral reflectance curves from March through October showing changes in reflectance patterns (400-750 nm) associated with varying anthocyanin concentrations (labeled in nmol/cm²). Spring months (March-April) show elevated anthocyanin in developing leaves, summer months (May-August) display minimal anthocyanin in mature leaves, and autumn months (September-October) exhibit dramatic anthocyanin accumulation during senescence. The green-yellow region (500-650 nm) shows progressive absorption with increasing anthocyanin content. Source: Gitelson et al., 2006.\n\n\n\nThe temporal dynamics of anthocyanin accumulation are particularly striking. Figure 3 displays spectral reflectance patterns across the growing season (March through October) with varying anthocyanin concentrations labeled on each panel. Key observations include:\n\nSpring accumulation (March-April): Young, developing leaves often contain elevated anthocyanins (15-35 nmol/cm²) for photoprotection during leaf expansion (Steyn et al. 2002)\nSummer reduction (May-August): Mature leaves typically maintain low anthocyanin levels (&lt;7 nmol/cm²) when plants are unstressed\nAutumn senescence (September-October): Dramatic anthocyanin accumulation (up to 24 nmol/cm²) as chlorophyll degrades and autumn coloration develops (Hoch, Zeldin, and McCown 2001)\n\nThe spectral manifestation of these changes is clearly visible in the green-yellow region (500-600 nm), where increasing anthocyanin content progressively suppresses reflectance. This seasonal pattern makes anthocyanin indices valuable for phenological monitoring and stress detection (Gitelson and N 1996)."
  },
  {
    "objectID": "topics/hyperspectral_theory.html#concentration-dependent-spectral-response",
    "href": "topics/hyperspectral_theory.html#concentration-dependent-spectral-response",
    "title": "Theoretical Background: Hyperspectral Remote Sensing of Plant Functional Traits",
    "section": "4 Concentration-Dependent Spectral Response",
    "text": "4 Concentration-Dependent Spectral Response\nThe relationship between biochemical concentration and spectral reflectance follows predictable patterns that enable quantitative remote sensing (Jacquemoud and Baret 1990). Figure 4 provides a comprehensive demonstration of this relationship for chlorophylls and carotenoids.\n\n\n\n\n\n\nFigure 4: Concentration-dependent spectral response of chlorophylls and carotenoids. a: Pigment content (nmol/cm²) for chlorophyll (Chl, green bars) and carotenoids (Car, yellow bars) across seven groups with increasing chlorophyll dominance. b: Corresponding spectral reflectance curves (400-750 nm) for each concentration group, showing systematic changes in reflectance magnitude and spectral shape. Source: Gitelson et al., 2006.\n\n\n\nThe left panel of Figure 4 shows chlorophyll (Chl, green bars) and carotenoid (Car, yellow bars) concentrations across seven groups with increasing biochemical content and chlorophyll dominance. Group 7 contains approximately 35 nmol/cm² of chlorophyll and 10 nmol/cm² of carotenoids, representing dense, healthy foliage, while Group 1 has minimal pigment content dominated by carotenoids, which is characteristic of stressed or senescent tissue.\nThe right panel shows how these concentration differences manifest in spectral reflectance (400-750 nm). The numbered curves (1-7) correspond to the concentration groups, revealing several critical patterns:\n\nBlue region (400-500 nm): All curves show low reflectance due to combined chlorophyll and carotenoid absorption, with minimal differentiation between concentration levels.\nGreen peak (520-570 nm): Increasing pigment concentrations progressively suppress the green reflectance peak, but this region shows modest dynamic range.\nRed absorption (650-690 nm): Deep absorption trough that deepens only slightly with increasing chlorophyll concentration due to saturation effects.\nRed edge (690-750 nm): The most dramatic differentiation occurs here, where the slope and position of the red edge shift systematically with chlorophyll content (Horler, Dockray, and Barber 1983).\n\nNote the near-linear spacing of curves as pigment concentration increases in the red edge region. This high sensitivity in the red edge makes it the most valuable spectral region for chlorophyll estimation (Gitelson and Merzlyak 2006). The physical explanation involves the transition from strong chlorophyll absorption in the red to minimal absorption in the near-infrared, creating a steep gradient that shifts in both position (red edge position) and amplitude with changing chlorophyll content.\nThis concentration-reflectance relationship forms the empirical foundation for vegetation indices and regression-based retrieval algorithms (Verrelst et al. 2015). However, the relationships are not always linear due to:\n\nSaturation effects: At high pigment concentrations, absorption becomes nearly complete, reducing sensitivity (Gitelson, Gritz, and Merzlyak 2003).\nMultiple scattering: Photon path length through leaf tissue affects the absorption probability.\nPackage effects: Pigments organized in chloroplasts rather than uniformly distributed. (Jacquemoud and Baret 1990)\nStructural confounding: Leaf thickness, internal air spaces, and surface properties modulate reflectance independently of biochemistry (Asner 1998)."
  },
  {
    "objectID": "topics/hyperspectral_theory.html#phenological-stages-and-stress-detection",
    "href": "topics/hyperspectral_theory.html#phenological-stages-and-stress-detection",
    "title": "Theoretical Background: Hyperspectral Remote Sensing of Plant Functional Traits",
    "section": "5 Phenological Stages and Stress Detection",
    "text": "5 Phenological Stages and Stress Detection\nAs we stated above, the appearance of foliage across developmental stages and stress conditions creates distinct spectral signatures that enable phenological monitoring and early stress detection (Carter 1993). Figure 5 presents a comprehensive comparison of three critical vegetation states: green (healthy) leaves, yellow-reddish (stress/senescence) leaves, and red (early development) leaves.\n\n\n\n\n\n\nFigure 5: Spectral signatures of leaves at different phenological stages and stress conditions. Top left: Green (healthy) leaves showing characteristic chlorophyll absorption in blue and red regions with prominent green peak and near-infrared plateau. Top right: Yellow-reddish leaves representing early senescence or stress conditions with elevated visible reflectance and reduced red absorption. Bottom: Red leaves indicating advanced senescence with strong anthocyanin absorption in green-yellow region, minimal chlorophyll absorption, and complete loss of red edge feature. Colored bullet points indicate developmental stage: red (beginning of vegetation), green (healthy development), and yellow-orange (stress/senescence). Source: Gitelson et al., 2006.\n\n\n\n\n5.1 Green Leaves: The Baseline Healthy Signature\nThe green leaf spectra (top left, Figure 5) exhibit the classic vegetation signature (Gates et al. 1965):\n\nLow reflectance in blue (400-500 nm) and red (600-680 nm) due to chlorophyll absorption\nModest green peak around 550 nm where chlorophyll absorption is minimal\nSharp red edge transition (690-750 nm)\nHigh near-infrared plateau (750-800 nm) determined by leaf internal structure\n\nMultiple curves represent natural variability within healthy vegetation—different species, leaf ages, or environmental conditions—but all share the fundamental pattern of strong chlorophyll absorption bracketing the green reflectance peak. This signature corresponds to the “Development (healthy)” stage marked in green on the figure, representing peak photosynthetic activity and optimal physiological function (Peñuelas et al. 1993).\n\n\n5.2 Yellow-Reddish Leaves: Stress and Senescence\nThe yellow-reddish leaf spectra (top right, Figure 5) show systematic departures from the healthy baseline:\n\nElevated reflectance across the entire visible spectrum (400-700 nm) as chlorophyll degrades\nBroadened and increased green-yellow reflectance (500-600 nm) revealing underlying carotenoids\nReduced red absorption depth as chlorophyll concentration declines\nGentler red edge slope indicating lower chlorophyll content\nSlightly reduced near-infrared reflectance in some cases, suggesting changes in leaf internal structure\n\nThese spectral changes correspond to stress or senescence conditions (marked in yellow-orange bullets on the figure) where chlorophyll synthesis is impaired or degradation accelerated (Carter 1993). During stress or senescence, chlorophyll degrades while carotenoids persist longer, creating the characteristic yellow-orange appearance.\n\n\n5.3 Red Leaves: Beginning of Vegetation\nThe red leaf spectra (bottom, Figure 5) represent young, developing leaves at the beginning of the growing season:\n\nElevated visible reflectance (400-700 nm) due to lower chlorophyll content in developing leaves\nStrong absorption in green-yellow region (520-600 nm) from anthocyanin accumulation\nModerate red absorption as chlorophyll is still developing\nLess pronounced red edge compared to mature leaves due to lower chlorophyll content\nLower near-infrared reflectance than mature leaves, reflecting developing leaf structure\n\nThis spectral signature, marked as “Beginning of vegetation” with red bullets in the figure, indicates early spring leaf development where anthocyanins accumulate for photoprotection while the photosynthetic apparatus is still maturing (Steyn et al. 2002). Young leaves often produce anthocyanins to protect developing chloroplasts from photo-oxidative damage during the vulnerable expansion phase. As leaves mature and the photosynthetic machinery becomes fully functional, anthocyanin content typically decreases and chlorophyll dominates, transitioning to the green leaf signature.\n\n\n5.4 The Phenological Continuum\nThe progression from red (early development) through green (mature, healthy) to yellow-reddish (stress/senescence) leaves represents different physiological states that can be monitored remotely (Gitelson and Merzlyak 2001). Importantly, this highlights a challenge in remote sensing: both young developing leaves and senescing leaves can show elevated anthocyanin content, but for different physiological reasons. Distinguishing between these states requires temporal context—spring observations of red spectra likely indicate new growth, while autumn observations suggest senescence. Vegetation indices designed to capture these transitions must account for the changing relationships between pigments and the multiple roles of anthocyanins across the growing season (Richardson et al. 2018)."
  },
  {
    "objectID": "topics/hyperspectral_theory.html#structural-components-beyond-pigments",
    "href": "topics/hyperspectral_theory.html#structural-components-beyond-pigments",
    "title": "Theoretical Background: Hyperspectral Remote Sensing of Plant Functional Traits",
    "section": "6 Structural Components: Beyond Pigments",
    "text": "6 Structural Components: Beyond Pigments\nWhile pigments dominate the visible spectrum, structural and biochemical components beyond pigments create diagnostic features in the near-infrared and shortwave infrared regions (Curran 1989). Figure 6 focuses on epicuticular waxes, protective coatings on leaf surfaces that serve multiple functions including water regulation, pathogen defense, and UV protection. Similarly to chlorophyll, wax concentration is highest at the peak of the vegetation season.\n\n\n\n\n\n\nFigure 6: Impact of epicuticular wax on leaf spectral reflectance. a: Scanning electron microscopy (SEM) images showing leaf surface microstructure with intact epicuticular wax crystals (top row) and after wax removal (bottom row) at different times. b: Spectral reflectance curves (410-1710 nm) demonstrating the effect of wax removal on reflectance across visible, near-infrared, and shortwave infrared regions. Three curves show reflectance before wax removal (highest), after 10 seconds of removal (intermediate), and after 30 seconds of removal (lowest), with the greatest differences observed in the near-infrared region (750-1250 nm). Source: Kozhoridze et al. (2016)\n\n\n\nThe electron microscopy images in Figure 6 show dramatic differences in leaf surface structure before and after wax removal, revealing the crystalline wax structures that coat healthy leaf surfaces. The spectral consequences of wax removal are striking:\n\nBefore removal (top curve): Highest reflectance across the entire spectrum, particularly in the near-infrared (750-1700 nm) where wax creates a highly reflective surface\nAfter 10 seconds of removal: Intermediate reflectance as surface wax is partially dissolved\nAfter 30 seconds of removal (bottom curve): Lowest reflectance as most surface wax has been eliminated\n\nNotably, the wax removal experiment demonstrates the phenomenon of blue shift, where the reflectance spectrum shifts systematically toward shorter wavelengths as wax is removed. This blue shift occurs because epicuticular waxes preferentially scatter longer wavelengths; their removal reduces this scattering effect, causing the spectral curves to shift toward the blue end of the spectrum. This phenomenon has important implications for interpreting spectral changes in vegetation experiencing drought stress or other conditions that affect wax production or integrity.\nThe spectral regions most sensitive to wax content are:\n\nBlue-green (410-550 nm): Moderate sensitivity with elevated reflectance in waxy leaves\nNear-infrared (750-1250 nm): High sensitivity throughout this region\nShortwave infrared (1300-1700 nm): Continued sensitivity to wax content\n\nThe practical implication is that vegetation indices targeting wax content must operate in spectral regions where wax effects dominate over pigment absorption. The reciprocal of the square root of reflectance differences in specific wavelength regions provides a measure of wax content:\n\\[\\frac{1}{\\sqrt{R_{750-770} - R_{490-500} - R_{660-690}}}\\]\nBeyond waxes, other structural components create diagnostic spectral features:\n\nCellulose and lignin: Absorption bands in the shortwave infrared around 2100 nm (Curran 1989)\nLeaf water content: Strong absorption features at 970 nm, 1200 nm, 1450 nm, and 1940 nm (Peñuelas et al. 1993)\nLeaf internal structure: Determines the overall magnitude of near-infrared reflectance through multiple scattering (Jacquemoud and Baret 1990)\n\nThese structural and compositional properties interact with pigment signals, creating the full complexity of vegetation spectra that extends from 400 nm through 2500 nm in comprehensive hyperspectral datasets (Ustin and Gamon 2010)."
  },
  {
    "objectID": "topics/hyperspectral_theory.html#from-spectral-signatures-to-quantitative-estimation",
    "href": "topics/hyperspectral_theory.html#from-spectral-signatures-to-quantitative-estimation",
    "title": "Theoretical Background: Hyperspectral Remote Sensing of Plant Functional Traits",
    "section": "7 From Spectral Signatures to Quantitative Estimation",
    "text": "7 From Spectral Signatures to Quantitative Estimation\nThe theoretical framework presented here—linking specific biochemical compounds to characteristic spectral features—forms the foundation for quantitative remote sensing of vegetation functional traits (Homolová et al. 2013). The key principles that enable this translation from photons to plant physiology are:\n\nSpectral specificity: Each compound has characteristic absorption features at particular wavelengths, enabling selective detection (Gates et al. 1965)\nConcentration dependence: Reflectance changes systematically with biochemical concentration, allowing quantitative estimation (Jacquemoud and Baret 1990)\nTemporal dynamics: Seasonal patterns in biochemistry create predictable spectral trajectories (Richardson et al. 2018)\nStructural modulation: Leaf and canopy architecture affect spectral signals independently of biochemistry, requiring normalization strategies (Asner 1998)\n\nThe practical implementation of these principles through vegetation indices and statistical models—demonstrated in the following tutorial sections—provides operational tools for extracting biological information from hyperspectral data (Verrelst et al. 2015). By understanding the physical and physiological basis of these spectral-biochemical relationships, researchers can develop robust methods for monitoring plant functional traits across scales, from controlled laboratory measurements to satellite-based global vegetation monitoring (Ustin and Gamon 2010).\n\nThis theoretical foundation prepares you to interpret the analytical methods demonstrated in the practical tutorial that follows, where we transform raw spectral measurements into quantitative estimates of plant functional traits through statistical analysis and machine learning classification."
  },
  {
    "objectID": "topics/hyperspectral_theory.html#references",
    "href": "topics/hyperspectral_theory.html#references",
    "title": "Theoretical Background: Hyperspectral Remote Sensing of Plant Functional Traits",
    "section": "8 References",
    "text": "8 References\n\n\nAsner, Gregory P. 1998. “Biophysical and Biochemical Sources of Variability in Canopy Reflectance.” Remote Sensing of Environment 64 (3): 234–53.\n\n\nAsner, Gregory P, and Roberta E Martin. 2015. “Quantifying Forest Canopy Traits: Imaging Spectroscopy Versus Field Survey.” Remote Sensing of Environment 158: 15–27.\n\n\nCarter, Gregory A. 1993. “Responses of Leaf Spectral Reflectance to Plant Stress.” American Journal of Botany 81 (2): 239–43.\n\n\nCurran, Paul J. 1989. “Remote Sensing of Foliar Chemistry.” Remote Sensing of Environment 30 (3): 271–78.\n\n\nDemmig-Adams, Barbara, and William W Adams III. 2006. “Photoprotection in an Ecological Context: The Remarkable Complexity of Thermal Energy Dissipation.” New Phytologist 172 (1): 11–21.\n\n\nGates, David M, Harry J Keegan, John C Schleter, and Victor R Weidner. 1965. “Spectral Properties of Plants.” Applied Optics 4 (1): 11–20.\n\n\nGitelson, Anatoly A, Yuri Gritz, and Mark N Merzlyak. 2003. “Relationships Between Leaf Chlorophyll Content and Spectral Reflectance and Algorithms for Non-Destructive Chlorophyll Assessment in Higher Plant Leaves.” Journal of Plant Physiology 160 (3): 271–82.\n\n\nGitelson, Anatoly A, Yoram J Kaufman, Robert Stark, and Don Rundquist. 2002. “Novel Algorithms for Remote Estimation of Vegetation Fraction.” Remote Sensing of Environment 80 (1): 76–87.\n\n\nGitelson, Anatoly A, Galina P Keydan, and Mark N Merzlyak. 2006. “Three-Band Model for Noninvasive Estimation of Chlorophyll, Carotenoids, and Anthocyanin Contents in Higher Plant Leaves.” Geophysical Research Letters 33 (11).\n\n\nGitelson, Anatoly A, and Mark N Merzlyak. 2001. “Non-Destructive Assessment of Chlorophyll Carotenoid and Anthocyanin Content in Higher Plant Leaves: Principles and Algorithms.” Remote Sensing for Agriculture and the Environment 1: 78–94.\n\n\n———. 2006. “Remote Estimation of Chlorophyll Content in Higher Plant Leaves.” International Journal of Remote Sensing 27 (12): 2055–66.\n\n\nGitelson, Anatoly A, and Merzylak Mark N. 1996. “Signature Analysis of Leaf Reflectance Spectra: Algorithm Development for Remote Sensing of Chlorophyll.” Journal of Plant Physiology 163 (3): 1176–85.\n\n\nGould, Kevin S. 2004. “Nature’s Swiss Army Knife: The Diverse Protective Roles of Anthocyanins in Leaves.” Journal of Biomedicine and Biotechnology 2004 (5): 314–20.\n\n\nHoch, William A, Erika L Zeldin, and Brent H McCown. 2001. “Physiological Significance of Anthocyanins During Autumnal Leaf Senescence.” Tree Physiology 21 (1): 1–8.\n\n\nHomolová, Lucie, Zbyněk Malenovský, JGPW Clevers, Glenda Garcı́a-Santos, and Michael E Schaepman. 2013. “Review of Optical-Based Remote Sensing for Plant Trait Mapping.” Ecological Complexity 15: 1–16.\n\n\nHorler, DNH, M Dockray, and J Barber. 1983. “The Red Edge of Plant Leaf Reflectance.” International Journal of Remote Sensing 4 (2): 273–88.\n\n\nHuete, Alfredo, Kamel Didan, Tomoaki Miura, E Patricia Rodriguez, Xiang Gao, and Laerte G Ferreira. 2002. “Overview of the Radiometric and Biophysical Performance of the MODIS Vegetation Indices.” Remote Sensing of Environment 83 (1-2): 195–213.\n\n\nJacquemoud, Stéphane, and Frédéric Baret. 1990. “PROSPECT: A Model of Leaf Optical Properties Spectra.” Remote Sensing of Environment 34 (2): 75–91.\n\n\nKozhoridze, Giorgi, Nikolai Orlovsky, Leah Orlovsky, Dan G Blumberg, and Avi Golan-Goldhirsh. 2016. “Remote Sensing Models of Structure-Related Biochemicals and Pigments for Classification of Trees.” Remote Sensing of Environment 186: 184–95.\n\n\nLichtenthaler, Hartmut K. 1987. “Chlorophylls and Carotenoids: Pigments of Photosynthetic Biomembranes.” Methods in Enzymology 148: 350–82.\n\n\nMerzlyak, Mark N, Anatoly A Gitelson, and Olga B Chivkunova. 1999. “Non-Destructive Optical Detection of Pigment Changes During Leaf Senescence and Fruit Ripening.” Physiologia Plantarum 106 (1): 135–41.\n\n\nPeñuelas, Josep, Iolanda Filella, Corina Biel, Lluis Serrano, and Robert Save. 1993. “The Reflectance at the 950–970 Nm Region as an Indicator of Plant Water Status.” International Journal of Remote Sensing 14 (10): 1887–1905.\n\n\nRichardson, Andrew D, Mariah S Carbone, Trevor F Keenan, Claudia I Czimczik, David Y Hollinger, Patty Murakami, Paul G Schaberg, and Xiaomei Xu. 2013. “Seasonal Dynamics and Age of Stemwood Nonstructural Carbohydrates in Temperate Forest Trees.” New Phytologist 197 (3): 850–61.\n\n\nRichardson, Andrew D, Koen Hufkens, Tom Milliman, Donald M Aubrecht, Min Chen, Josh M Gray, Miriam R Johnston, et al. 2018. “Tracking Vegetation Phenology Across Diverse North American Biomes Using PhenoCam Imagery.” Scientific Data 5 (1): 1–24.\n\n\nSteyn, Wibke JA, SJE Wand, DM Holcroft, and Gerhard Jacobs. 2002. “Anthocyanins in Vegetative Tissues: A Proposed Unified Function in Photoprotection.” New Phytologist 155 (3): 349–61.\n\n\nUstin, Susan L, and John A Gamon. 2010. “Remote Sensing of Plant Functional Types.” New Phytologist 186 (4): 795–816.\n\n\nVerrelst, J, Z Malenovský, C Van der Tol, G Camps-Valls, JP Gastellu-Etchegorry, P Lewis, P North, and J Moreno. 2015. “Optical Remote Sensing and the Retrieval of Terrestrial Vegetation Bio-Geophysical Properties–a Review.” ISPRS Journal of Photogrammetry and Remote Sensing 108: 273–90."
  },
  {
    "objectID": "topics/python_lesson.html",
    "href": "topics/python_lesson.html",
    "title": "Python Lesson",
    "section": "",
    "text": "Python: Intro to Remote Sensing\nIn this lesson, you will run and explore the following Python notebook.\nLaunch in Binder\nDownload Notebook\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nplt.plot(x, y)\nplt.title(\"Sine Wave\")\nplt.show()\n\nWatch the video below:"
  }
]