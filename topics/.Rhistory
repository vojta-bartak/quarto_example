# Create visualization of classification space
scores_all <- plsda_model$variates$X[, 1:2]  # First two components
plot_df <- data.frame(scores_all, Class = Y)
colnames(plot_df)[1:2] <- c("Comp.1", "Comp.2")
# Generate plot
p <- ggplot(plot_df, aes(x = Comp.1, y = Comp.2, color = Class)) +
geom_point(size = 3) +
geom_mark_ellipse(aes(fill = Class), alpha = 0.2, show.legend = FALSE) +
theme_minimal() +
ggtitle(sprintf("%s - OA=%.3f, Kappa=%.3f", month, OA, Kappa)) +
theme(plot.title = element_text(hjust = 0.5))
return(list(plot = p, OA = OA, Kappa = Kappa))
p
pred_out
pred_out$class
colnames(data)
#| label: load-data
#| eval: true
# Load the hyperspectral data
data <- read.csv("SamplesForWorkshop.csv")
# Inspect the basic structure
head(data[,1:21])
colnames(data)
run_plsda_for_month <- function(data, month) {
# Subset data for specific month
df <- subset(data, Month == month)
df <- df[, !duplicated(names(df))]
# Extract spectral columns and class labels
spec_cols <- grep("^X\\d{3,4}$", names(df))
X <- as.matrix(df[, spec_cols])  # Predictor matrix (spectral data)
Y <- factor(df$Class)           # Response vector (plant classes)
# Fit PLS-DA model
plsda_model <- plsda(X, Y, ncomp = 3)
# Make predictions
pred_out <- predict(plsda_model, X)
pred <- if (is.list(pred_out) && "class" %in% names(pred_out)) {
pred_out$class$max.dist[, 2]  # Use component 2
} else {
as.factor(pred_out)
}
# Calculate accuracy metrics
cm <- confusionMatrix(factor(pred, levels = levels(Y)), Y)
OA <- cm$overall["Accuracy"]      # Overall Accuracy
Kappa <- cm$overall["Kappa"]      # Cohen's Kappa
# Create visualization of classification space
scores_all <- plsda_model$variates$X[, 1:2]  # First two components
plot_df <- data.frame(scores_all, Class = Y)
colnames(plot_df)[1:2] <- c("Comp.1", "Comp.2")
# Generate plot
p <- ggplot(plot_df, aes(x = Comp.1, y = Comp.2, color = Class)) +
geom_point(size = 3) +
geom_mark_ellipse(aes(fill = Class), alpha = 0.2, show.legend = FALSE) +
theme_minimal() +
ggtitle(sprintf("%s - OA=%.3f, Kappa=%.3f", month, OA, Kappa)) +
theme(plot.title = element_text(hjust = 0.5))
return(list(plot = p, OA = OA, Kappa = Kappa))
}
```{r run-classification}
#| label: run-plsda-classification
#| fig-cap: "PLS-DA classification results using full spectral data"
#| fig-width: 12
#| fig-height: 5
#| eval: true
# Subset data by month
Class_Data_Scaled_M <- subset(Class_Data_Scaled, Month == "March")
Class_Data_Scaled_J <- subset(Class_Data_Scaled, Month == "July")
# Run PLS-DA for each month
march_res <- run_plsda_for_month(Class_Data_Scaled_M, "March")
july_res <- run_plsda_for_month(Class_Data_Scaled_J, "July")
# Display results
combined_plot <- march_res$plot + july_res$plot + plot_layout(ncol = 2)
print(combined_plot)
# Plot VIP scores
vip_plot <- ggplot(vip_long, aes(x = Variable, y = VIP, fill = Month)) +
geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
theme_minimal() +
labs(title = "VIP Scores Comparison: March vs July",
y = "VIP Score", x = NULL, fill = "Month") +
scale_x_discrete(labels = vip_long$Label) +
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7)) +
facet_grid(. ~ WavelengthGroup, scales = "free_x", space = "free_x")
#| label: vip-analysis-spectral
#| fig-cap: "Variable Importance in Projection (VIP) scores for spectral bands"
#| fig-width: 14
#| fig-height: 6
#| eval: true
# Function to extract VIP scores
run_plsda_and_get_vip <- function(data, month, ncomp = 3) {
df <- subset(data, Month == month)
df <- df[, !duplicated(names(df))]
spec_cols <- grep("^X\\d{3,4}$", names(df))
X <- as.matrix(df[, spec_cols])
Y <- factor(df$Class)
plsda_model <- mixOmics::plsda(X, Y, ncomp = ncomp)
vip_scores <- mixOmics::vip(plsda_model)[,1]  # VIP for first component
return(list(model = plsda_model, VIP = vip_scores))
}
# Extract VIP scores for both months
march_VIP <- run_plsda_and_get_vip(Class_Data_Scaled_M, "March")
july_VIP <- run_plsda_and_get_vip(Class_Data_Scaled_J, "July")
# Prepare VIP data for visualization
vip_df <- data.frame(
Variable = names(march_VIP$VIP),
March = as.numeric(march_VIP$VIP),
July = as.numeric(july_VIP$VIP)
)
vip_long <- vip_df %>%
pivot_longer(cols = c("March", "July"), names_to = "Month", values_to = "VIP")
# Add wavelength information and spectral regions
vip_long$Wavelength <- as.numeric(gsub("X", "", vip_long$Variable))
vip_long$WavelengthGroup <- cut(
vip_long$Wavelength,
breaks = c(399, 700, 1300, 2400),
labels = c("VIS (400–700)", "NIR (701–1300)", "SWIR (1301–2400)")
)
# Create labels for every 100 nm
vip_long$Label <- ifelse(vip_long$Wavelength %% 100 == 0,
paste0(vip_long$Wavelength, " nm"), "")
# Order variables by wavelength
ordered_vars <- vip_long %>%
distinct(Variable, Wavelength) %>%
arrange(Wavelength) %>%
pull(Variable)
vip_long$Variable <- factor(vip_long$Variable, levels = ordered_vars)
# Plot VIP scores
vip_plot <- ggplot(vip_long, aes(x = Variable, y = VIP, fill = Month)) +
geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
theme_minimal() +
labs(title = "VIP Scores Comparison: March vs July",
y = "VIP Score", x = NULL, fill = "Month") +
scale_x_discrete(labels = vip_long$Label) +
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7)) +
facet_grid(. ~ WavelengthGroup, scales = "free_x", space = "free_x")
print(vip_plot)
#| label: calculate-vegetation-indices
#| eval: true
# Define wavelength ranges for index calculations
cols_750_770 <- paste0("X", 750:770)
cols_490_500 <- paste0("X", 490:500)
cols_660_690 <- paste0("X", 660:690)
cols_690_720 <- paste0("X", 690:720)
cols_760_800 <- paste0("X", 760:800)
cols_510_520 <- paste0("X", 510:520)
cols_690_710 <- paste0("X", 690:710)
cols_530_570 <- paste0("X", 540:560)
# Calculate mean reflectance for each range
mean_750_770 <- rowMeans(data[, cols_750_770], na.rm = TRUE)
mean_490_500 <- rowMeans(data[, cols_490_500], na.rm = TRUE)
mean_660_690 <- rowMeans(data[, cols_660_690], na.rm = TRUE)
mean_690_720 <- rowMeans(data[, cols_690_720], na.rm = TRUE)
mean_760_800 <- rowMeans(data[, cols_760_800], na.rm = TRUE)
mean_510_520 <- rowMeans(data[, cols_510_520], na.rm = TRUE)
mean_690_710 <- rowMeans(data[, cols_690_710], na.rm = TRUE)
mean_530_570 <- rowMeans(data[, cols_530_570], na.rm = TRUE)
# Calculate vegetation indices
VI_Chl <- (1/mean_690_720 - 1/mean_760_800) * mean_760_800      # Chlorophyll index
VI_C <- (1/mean_510_520 - 1/mean_690_710) * mean_760_800        # Carbon index
VI_Antho <- (1/mean_530_570 - 1/mean_690_710) * mean_760_800    # Anthocyanin index
VI_Cell <- with(data, 100 * (0.5 * (X2030 + X2210) - X2100))   # Cellulose index
VI_Wax <- 1 / sqrt(mean_750_770 - mean_490_500 - mean_660_690)  # Wax index
# Add indices to dataset
data$VI_Chl <- VI_Chl
data$VI_C <- VI_C
data$VI_Antho <- VI_Antho
data$VI_Cell <- VI_Cell
data$VI_Wax <- VI_Wax
#| label: classification-with-indices
#| fig-cap: "PLS-DA classification results using vegetation indices"
#| fig-width: 12
#| fig-height: 5
#| eval: true
# Prepare index-based classification data
ClassData <- subset(data, select = c("Month", "Group", "Class",
"VI_Chl", "VI_C", "VI_Antho", "VI_Cell", "VI_Wax"))
# Scale indices separately for each month
MarchData <- scale(ClassData[1:15, 4:8])
JulyData <- scale(ClassData[16:30, 4:8])
Class_Data_Scaled <- rbind(MarchData, JulyData)
Class_Data_Scaled <- cbind(ClassData[, 1:3], Class_Data_Scaled)
# Modified PLS-DA function for vegetation indices
run_plsda_for_month_indices <- function(data, month) {
df <- subset(data, Month == month)
df <- df[, !duplicated(names(df))]
vi_cols <- grep("^VI_", names(df))
X <- as.matrix(df[, vi_cols])
Y <- factor(df$Class)
plsda_model <- plsda(X, Y, ncomp = 3)
pred_out <- predict(plsda_model, X)
pred <- if (is.list(pred_out) && "class" %in% names(pred_out)) {
pred_out$class$max.dist[, 2]
} else {
as.factor(pred_out)
}
cm <- confusionMatrix(factor(pred, levels = levels(Y)), Y)
OA <- cm$overall["Accuracy"]
Kappa <- cm$overall["Kappa"]
scores_all <- plsda_model$variates$X[, 1:2]
plot_df <- data.frame(scores_all, Class = Y)
colnames(plot_df)[1:2] <- c("Comp.1", "Comp.2")
p <- ggplot(plot_df, aes(x = Comp.1, y = Comp.2, color = Class)) +
geom_point(size = 3) +
geom_mark_ellipse(aes(fill = Class), alpha = 0.2, show.legend = FALSE) +
theme_minimal() +
ggtitle(sprintf("%s - OA=%.3f, Kappa=%.3f", month, OA, Kappa)) +
theme(plot.title = element_text(hjust = 0.5))
return(list(plot = p, OA = OA, Kappa = Kappa))
}
# Run classification with indices
Class_Data_Scaled_M <- subset(Class_Data_Scaled, Month == "March")
Class_Data_Scaled_J <- subset(Class_Data_Scaled, Month == "July")
march_res <- run_plsda_for_month_indices(Class_Data_Scaled_M, "March")
july_res <- run_plsda_for_month_indices(Class_Data_Scaled_J, "July")
combined_plot <- march_res$plot + july_res$plot + plot_layout(ncol = 2)
print(combined_plot)
#| label: vip-analysis-indices
#| fig-cap: "VIP scores for vegetation indices"
#| fig-width: 10
#| fig-height: 6
#| eval: true
# VIP analysis for vegetation indices
run_plsda_and_get_vip_indices <- function(data, month, ncomp = 3) {
df <- subset(data, Month == month)
df <- df[, !duplicated(names(df))]
vi_cols <- grep("^VI_", names(df))
X <- as.matrix(df[, vi_cols])
Y <- factor(df$Class)
plsda_model <- mixOmics::plsda(X, Y, ncomp = ncomp)
vip_scores <- mixOmics::vip(plsda_model)[,1]
return(list(model = plsda_model, VIP = vip_scores))
}
# Extract VIP scores
march_VIP <- run_plsda_and_get_vip_indices(Class_Data_Scaled_M, "March")
july_VIP <- run_plsda_and_get_vip_indices(Class_Data_Scaled_J, "July")
# Prepare and plot VIP data
vip_df <- data.frame(
Variable = names(march_VIP$VIP),
March = as.numeric(march_VIP$VIP),
July = as.numeric(july_VIP$VIP)
)
vip_long <- vip_df %>%
pivot_longer(cols = c("March", "July"), names_to = "Month", values_to = "VIP")
vip_plot <- ggplot(vip_long, aes(x = Variable, y = VIP, fill = Month)) +
geom_bar(stat = "identity", position = position_dodge(width = 0.8), width = 0.7) +
geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
geom_text(aes(label = round(VIP, 2)), position = position_dodge(width = 0.8),
vjust = -0.5, size = 3) +
theme_minimal() +
labs(title = "VIP Scores Comparison: March vs July (Vegetation Indices)",
y = "VIP Score", x = NULL, fill = "Month") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(vip_plot)
#| label: cross-validation-example
#| eval: true
# Example of k-fold cross-validation for PLS-DA
perform_cv_plsda <- function(data, k_folds = 5) {
# Prepare data
spec_cols <- grep("^X\\d{3,4}$", names(data))
X <- as.matrix(data[, spec_cols])
Y <- factor(data$Class)
# Create folds
folds <- createFolds(Y, k = k_folds, list = TRUE)
cv_results <- map_dfr(names(folds), function(fold_name) {
test_idx <- folds[[fold_name]]
train_idx <- setdiff(1:nrow(X), test_idx)
# Train model
plsda_model <- plsda(X[train_idx, ], Y[train_idx], ncomp = 3)
# Predict on test set
pred <- predict(plsda_model, X[test_idx, ])
pred_class <- pred$class[, 2]  # Use component 2
# Calculate metrics
cm <- confusionMatrix(factor(pred_class, levels = levels(Y)), Y[test_idx])
tibble(
fold = fold_name,
accuracy = cm$overall["Accuracy"],
kappa = cm$overall["Kappa"]
)
})
return(cv_results)
}
# Example usage (uncomment to run)
# march_data <- subset(Class_Data_Scaled, Month == "March")
# cv_results <- perform_cv_plsda(march_data)
# print(paste("Mean CV Accuracy:", round(mean(cv_results$accuracy), 3)))
#| label: cross-validation-example
#| eval: true
# Example of k-fold cross-validation for PLS-DA
perform_cv_plsda <- function(data, k_folds = 5) {
# Prepare data
spec_cols <- grep("^X\\d{3,4}$", names(data))
X <- as.matrix(data[, spec_cols])
Y <- factor(data$Class)
# Create folds
folds <- createFolds(Y, k = k_folds, list = TRUE)
cv_results <- map_dfr(names(folds), function(fold_name) {
test_idx <- folds[[fold_name]]
train_idx <- setdiff(1:nrow(X), test_idx)
# Train model
plsda_model <- plsda(X[train_idx, ], Y[train_idx], ncomp = 3)
# Predict on test set
pred <- predict(plsda_model, X[test_idx, ])
pred_class <- pred$class[, 2]  # Use component 2
# Calculate metrics
cm <- confusionMatrix(factor(pred_class, levels = levels(Y)), Y[test_idx])
tibble(
fold = fold_name,
accuracy = cm$overall["Accuracy"],
kappa = cm$overall["Kappa"]
)
})
return(cv_results)
}
# Example usage (uncomment to run)
march_data <- subset(Class_Data_Scaled, Month == "March")
cv_results <- perform_cv_plsda(march_data)
#| label: cross-validation-example
#| eval: true
# Example of k-fold cross-validation for PLS-DA
perform_cv_plsda <- function(data, k_folds = 5) {
# Prepare data
spec_cols <- grep("^X\\d{3,4}$", names(data))
X <- as.matrix(data[, spec_cols])
Y <- factor(data$Class)
# Create folds
folds <- createFolds(Y, k = k_folds, list = TRUE)
cv_results <- map_dfr(names(folds), function(fold_name) {
test_idx <- folds[[fold_name]]
train_idx <- setdiff(1:nrow(X), test_idx)
# Train model
plsda_model <- plsda(X[train_idx, ], Y[train_idx], ncomp = 3)
# Predict on test set
pred <- predict(plsda_model, X[test_idx, ])
pred_class <- pred$class$max.dist[, 2]  # Use component 2
# Calculate metrics
cm <- confusionMatrix(factor(pred_class, levels = levels(Y)), Y[test_idx])
tibble(
fold = fold_name,
accuracy = cm$overall["Accuracy"],
kappa = cm$overall["Kappa"]
)
})
return(cv_results)
}
# Example usage (uncomment to run)
march_data <- subset(Class_Data_Scaled, Month == "March")
cv_results <- perform_cv_plsda(march_data)
data <- march_data
k_folds <- 5
# Prepare data
spec_cols <- grep("^X\\d{3,4}$", names(data))
# Prepare data
spec_cols <- grep("^X\\d+$", names(data))
View(march_data)
# Example usage (uncomment to run)
march_data <- subset(Class_Data_Scaled, Month == "March")
# Prepare data
ind_cols <- grep("VI", names(data))
X <- as.matrix(data[, ind_cols])
Y <- factor(data$Class)
# Create folds
folds <- createFolds(Y, k = k_folds, list = TRUE)
cv_results <- map_dfr(names(folds), function(fold_name) {
test_idx <- folds[[fold_name]]
train_idx <- setdiff(1:nrow(X), test_idx)
# Train model
plsda_model <- plsda(X[train_idx, ], Y[train_idx], ncomp = 3)
# Predict on test set
pred <- predict(plsda_model, X[test_idx, ])
pred_class <- pred$class$max.dist[, 2]  # Use component 2
# Calculate metrics
cm <- confusionMatrix(factor(pred_class, levels = levels(Y)), Y[test_idx])
tibble(
fold = fold_name,
accuracy = cm$overall["Accuracy"],
kappa = cm$overall["Kappa"]
)
})
View(cv_results)
# Example of k-fold cross-validation for PLS-DA
perform_cv_plsda <- function(data, k_folds = 5) {
# Prepare data
ind_cols <- grep("VI", names(data))
X <- as.matrix(data[, ind_cols])
Y <- factor(data$Class)
# Create folds
folds <- createFolds(Y, k = k_folds, list = TRUE)
cv_results <- map_dfr(names(folds), function(fold_name) {
test_idx <- folds[[fold_name]]
train_idx <- setdiff(1:nrow(X), test_idx)
# Train model
plsda_model <- plsda(X[train_idx, ], Y[train_idx], ncomp = 3)
# Predict on test set
pred <- predict(plsda_model, X[test_idx, ])
pred_class <- pred$class$max.dist[, 2]  # Use component 2
# Calculate metrics
cm <- confusionMatrix(factor(pred_class, levels = levels(Y)), Y[test_idx])
tibble(
fold = fold_name,
accuracy = cm$overall["Accuracy"],
kappa = cm$overall["Kappa"]
)
})
return(cv_results)
}
# Example usage (uncomment to run)
march_data <- subset(Class_Data_Scaled, Month == "March")
cv_results <- perform_cv_plsda(march_data)
print(paste("Mean CV Accuracy:", round(mean(cv_results$accuracy), 3)))
#| label: advanced-viz
#| eval: true
# 3D visualization of spectral-temporal space
library(plotly)
create_3d_spectral_plot <- function(data) {
# Prepare data for 3D plotting
plot_data <- data %>%
select(Month, Class, contains("X")) %>%
# Use PCA to reduce to 3 dimensions for visualization
{
spec_cols <- grep("^X\\d{3,4}$", names(.))
pca_result <- prcomp(.[, spec_cols], scale = TRUE)
cbind(.[, 1:2], as.data.frame(pca_result$x[, 1:3]))
}
# Create 3D plot
plot_ly(plot_data,
x = ~PC1, y = ~PC2, z = ~PC3,
color = ~Class, symbol = ~Month,
type = "scatter3d", mode = "markers") %>%
layout(
title = "3D Spectral Space Visualization",
scene = list(
xaxis = list(title = "PC1"),
yaxis = list(title = "PC2"),
zaxis = list(title = "PC3")
)
)
}
# Interactive spectral signature plot
create_interactive_spectra <- function(data) {
# Prepare long format data
spec_data <- data %>%
select(Month, Class, contains("X")) %>%
pivot_longer(cols = contains("X"), names_to = "Wavelength", values_to = "Reflectance") %>%
mutate(Wavelength = as.numeric(str_remove(Wavelength, "^X"))) %>%
group_by(Month, Class, Wavelength) %>%
summarise(
MeanReflectance = mean(Reflectance, na.rm = TRUE),
SD = sd(Reflectance, na.rm = TRUE),
.groups = "drop"
)
# Create interactive plot
p <- ggplot(spec_data, aes(x = Wavelength, y = MeanReflectance,
color = Class, linetype = Month)) +
geom_line(size = 1) +
geom_ribbon(aes(ymin = MeanReflectance - SD, ymax = MeanReflectance + SD,
fill = Class), alpha = 0.2, linetype = 0) +
theme_minimal() +
labs(
title = "Interactive Spectral Signatures",
x = "Wavelength (nm)",
y = "Reflectance",
color = "Plant Class",
linetype = "Month"
)
ggplotly(p, tooltip = c("x", "y", "colour", "linetype"))
}
#| label: alternative-ml-methods
#| eval: true
# Random Forest example
library(randomForest)
run_random_forest <- function(data, month) {
df <- subset(data, Month == month)
spec_cols <- grep("^X\\d{3,4}$", names(df))
X <- df[, spec_cols]
Y <- factor(df$Class)
# Train Random Forest
rf_model <- randomForest(x = X, y = Y, ntree = 500, importance = TRUE)
# Get predictions
predictions <- predict(rf_model, X)
# Calculate accuracy
cm <- confusionMatrix(predictions, Y)
# Variable importance
importance_scores <- importance(rf_model, type = 1)
return(list(
model = rf_model,
accuracy = cm$overall["Accuracy"],
kappa = cm$overall["Kappa"],
importance = importance_scores
))
}
# Support Vector Machine example
library(e1071)
run_svm <- function(data, month) {
df <- subset(data, Month == month)
spec_cols <- grep("^X\\d{3,4}$", names(df))
# Combine features and response
svm_data <- cbind(df[, spec_cols], Class = factor(df$Class))
# Train SVM with RBF kernel
svm_model <- svm(Class ~ ., data = svm_data, kernel = "radial",
cost = 1, gamma = 1/ncol(df[, spec_cols]))
# Get predictions
predictions <- predict(svm_model, svm_data[, -ncol(svm_data)])
# Calculate accuracy
cm <- confusionMatrix(predictions, svm_data$Class)
return(list(
model = svm_model,
accuracy = cm$overall["Accuracy"],
kappa = cm$overall["Kappa"]
))
}
run_random_forest(data, month)
250*0.3
